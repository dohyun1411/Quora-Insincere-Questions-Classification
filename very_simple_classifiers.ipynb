{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.6.6",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "colab": {
      "name": "very-simple-classifier.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dohyun1411/Quora-Insincere-Questions-Classification/blob/preprocessing1/very_simple_classifier.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_uuid": "5fb07eae7b445e3bf358222065133a144b7c4ade",
        "id": "eXiDiC3YfYbf"
      },
      "source": [
        "Fork https://www.kaggle.com/christofhenkel/how-to-preprocessing-when-using-embeddings#"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_uuid": "2b5f2c75786e9b8194938a420438bc1166e55ec3",
        "id": "qfm_3lwofYbl"
      },
      "source": [
        "In this kernel I want to illustrate how I do come up with meaningful preprocessing when building deep learning NLP models. \n",
        "\n",
        "I start with two golden rules:\n",
        "\n",
        "1.  **Don't use standard preprocessing steps like stemming or stopword removal when you have pre-trained embeddings** \n",
        "\n",
        "Some of you might used standard preprocessing steps when doing word count based feature extraction (e.g. TFIDF) such as removing stopwords, stemming etc. \n",
        "The reason is simple: You loose valuable information, which would help your NN to figure things out.  \n",
        "\n",
        "2. **Get your vocabulary as close to the embeddings as possible**\n",
        "\n",
        "I will focus in this notebook, how to achieve that. For an example I take the GoogleNews pretrained embeddings, there is no deeper reason for this choice."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_uuid": "ec55ed96a9cab0ac75b22f9710c0393b17cfefd2",
        "id": "PP-SY1XBfYbm"
      },
      "source": [
        "We start with a neat little trick that enables us to see a progressbar when applying functions to a pandas Dataframe"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "b378958a9606ac48fe0dc54e24bed4cd503e0ac7",
        "execution": {
          "iopub.status.busy": "2021-06-01T20:04:25.627964Z",
          "iopub.execute_input": "2021-06-01T20:04:25.628602Z",
          "iopub.status.idle": "2021-06-01T20:04:25.645382Z",
          "shell.execute_reply.started": "2021-06-01T20:04:25.628514Z",
          "shell.execute_reply": "2021-06-01T20:04:25.644488Z"
        },
        "trusted": true,
        "id": "kDShVpGgfYbn"
      },
      "source": [
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "tqdm.pandas()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_uuid": "6e432bb170a329c79f58f78527bbbe4e857b2c41",
        "id": "oT9u_JrMfYbo"
      },
      "source": [
        "Lets load our data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "execution": {
          "iopub.status.busy": "2021-06-01T20:04:25.646777Z",
          "iopub.execute_input": "2021-06-01T20:04:25.647148Z",
          "iopub.status.idle": "2021-06-01T20:04:31.074468Z",
          "shell.execute_reply.started": "2021-06-01T20:04:25.647056Z",
          "shell.execute_reply": "2021-06-01T20:04:31.073704Z"
        },
        "trusted": true,
        "id": "USnAsG2TfYbp",
        "outputId": "26552bde-cb6b-4b92-f53e-afd948f36c33"
      },
      "source": [
        "train = pd.read_csv(\"../input/train.csv\")\n",
        "test = pd.read_csv(\"../input/test.csv\")\n",
        "print(\"Train shape : \",train.shape)\n",
        "print(\"Test shape : \",test.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train shape :  (1306122, 3)\n",
            "Test shape :  (375806, 2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_uuid": "59fd43e3727bd265df08d2d8254230c655c51f9d",
        "id": "ZJmdvA3XfYbs"
      },
      "source": [
        "I will use the following function to track our training vocabulary, which goes through all our text and counts the occurance of the contained words. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "3e050f2fa9668c765466d766cfd79720cf6cc819",
        "execution": {
          "iopub.status.busy": "2021-06-01T20:04:31.075674Z",
          "iopub.execute_input": "2021-06-01T20:04:31.076216Z",
          "iopub.status.idle": "2021-06-01T20:04:31.082004Z",
          "shell.execute_reply.started": "2021-06-01T20:04:31.076133Z",
          "shell.execute_reply": "2021-06-01T20:04:31.081113Z"
        },
        "trusted": true,
        "id": "jBOMnvOnfYbs"
      },
      "source": [
        "def build_vocab(sentences, verbose =  True):\n",
        "    \"\"\"\n",
        "    :param sentences: list of list of words\n",
        "    :return: dictionary of words and their count\n",
        "    \"\"\"\n",
        "    vocab = {}\n",
        "    for sentence in tqdm(sentences, disable = (not verbose)):\n",
        "        for word in sentence:\n",
        "            try:\n",
        "                vocab[word] += 1\n",
        "            except KeyError:\n",
        "                vocab[word] = 1\n",
        "    return vocab"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_uuid": "a453d10106aea7f6bf3f9bd952f2e02dd7a7472c",
        "id": "MPfbXDxdfYbt"
      },
      "source": [
        "So lets populate the vocabulary and display the first 5 elements and their count. Note that now we can use progess_apply to see progress bar"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
        "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
        "execution": {
          "iopub.status.busy": "2021-06-01T20:04:31.083293Z",
          "iopub.execute_input": "2021-06-01T20:04:31.083797Z",
          "iopub.status.idle": "2021-06-01T20:04:44.968454Z",
          "shell.execute_reply.started": "2021-06-01T20:04:31.083720Z",
          "shell.execute_reply": "2021-06-01T20:04:44.967415Z"
        },
        "trusted": true,
        "id": "gUs9sLhRfYbu",
        "outputId": "947dc62e-34ee-4e83-9342-943d0bc60f1e"
      },
      "source": [
        "sentences = train[\"question_text\"].progress_apply(lambda x: x.split()).values\n",
        "vocab = build_vocab(sentences)\n",
        "print({k: vocab[k] for k in list(vocab)[:5]})"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 1306122/1306122 [00:07<00:00, 184714.57it/s]\n",
            "100%|██████████| 1306122/1306122 [00:06<00:00, 193875.12it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "{'How': 261930, 'did': 33489, 'Quebec': 97, 'nationalists': 91, 'see': 9003}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_uuid": "c5c1c2c96aecd40e969f13913e850a36d8e3a13d",
        "id": "E5AlNbVnfYbu"
      },
      "source": [
        "Next we import the embeddings we want to use in our model later. For illustration I use GoogleNews here."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "807e734e0ce617480c824f8bf26f0672f38397d5",
        "execution": {
          "iopub.status.busy": "2021-06-01T20:04:44.969593Z",
          "iopub.execute_input": "2021-06-01T20:04:44.969839Z",
          "iopub.status.idle": "2021-06-01T20:07:11.755281Z",
          "shell.execute_reply.started": "2021-06-01T20:04:44.969791Z",
          "shell.execute_reply": "2021-06-01T20:07:11.754343Z"
        },
        "trusted": true,
        "id": "ba60INMifYbv",
        "outputId": "9dec10f1-0511-4cfa-9f8e-e857a882106f"
      },
      "source": [
        "%%time\n",
        "import zipfile\n",
        "from gensim.models import KeyedVectors\n",
        "\n",
        "embeddings_path = '../input/embeddings.zip'\n",
        "google = 'GoogleNews-vectors-negative300/GoogleNews-vectors-negative300.bin'\n",
        "\n",
        "with zipfile.ZipFile(embeddings_path) as embedding_zip:\n",
        "    print(\"Found embeddings as a zip file\")\n",
        "    google_embeddings = KeyedVectors.load_word2vec_format(embedding_zip.open(google), binary=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found embeddings as a zip file\n",
            "CPU times: user 2min 6s, sys: 4.94 s, total: 2min 11s\n",
            "Wall time: 2min 26s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-06-01T20:07:11.756787Z",
          "iopub.execute_input": "2021-06-01T20:07:11.757150Z",
          "iopub.status.idle": "2021-06-01T20:07:11.761513Z",
          "shell.execute_reply.started": "2021-06-01T20:07:11.757053Z",
          "shell.execute_reply": "2021-06-01T20:07:11.760535Z"
        },
        "trusted": true,
        "id": "icjXmDdRfYbw"
      },
      "source": [
        "embeddings_index = google_embeddings"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_uuid": "b5f9048e53a5cb91bdaa518d33fda756f1038562",
        "id": "pS9XtI2pfYbw"
      },
      "source": [
        "Next I define a function that checks the intersection between our vocabulary and the embeddings. It will output a list of out of vocabulary (oov) words that we can use to improve our preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "f35a7213fc9a7e80a7c210d11b3a8094d3a8e07e",
        "execution": {
          "iopub.status.busy": "2021-06-01T20:07:11.762950Z",
          "iopub.execute_input": "2021-06-01T20:07:11.763302Z",
          "iopub.status.idle": "2021-06-01T20:07:11.774973Z",
          "shell.execute_reply.started": "2021-06-01T20:07:11.763234Z",
          "shell.execute_reply": "2021-06-01T20:07:11.774045Z"
        },
        "trusted": true,
        "id": "mgo592FjfYbx"
      },
      "source": [
        "import operator \n",
        "\n",
        "def check_coverage(vocab,embeddings_index):\n",
        "    a = {}\n",
        "    oov = {}\n",
        "    k = 0\n",
        "    i = 0\n",
        "    for word in tqdm(vocab):\n",
        "        try:\n",
        "            a[word] = embeddings_index[word]\n",
        "            k += vocab[word]\n",
        "        except:\n",
        "\n",
        "            oov[word] = vocab[word]\n",
        "            i += vocab[word]\n",
        "            pass\n",
        "\n",
        "    print('Found embeddings for {:.2%} of vocab'.format(len(a) / len(vocab)))\n",
        "    print('Found embeddings for  {:.2%} of all text'.format(k / (k + i)))\n",
        "    sorted_x = sorted(oov.items(), key=operator.itemgetter(1))[::-1]\n",
        "\n",
        "    return sorted_x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "42c2b82740ac82f5678a46b7c82b5525616c1304",
        "execution": {
          "iopub.status.busy": "2021-06-01T20:07:11.776347Z",
          "iopub.execute_input": "2021-06-01T20:07:11.776677Z",
          "iopub.status.idle": "2021-06-01T20:07:13.922835Z",
          "shell.execute_reply.started": "2021-06-01T20:07:11.776616Z",
          "shell.execute_reply": "2021-06-01T20:07:13.921948Z"
        },
        "trusted": true,
        "id": "kJxdpc8pfYbx",
        "outputId": "edafeb92-1e18-45b6-ea9f-711aaae6f2aa"
      },
      "source": [
        "oov = check_coverage(vocab,embeddings_index)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 508823/508823 [00:01<00:00, 262648.61it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Found embeddings for 24.31% of vocab\n",
            "Found embeddings for  78.75% of all text\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_uuid": "9ff8e507e571e671ed4249a95fb0eb339098446e",
        "id": "zh3RabAafYby"
      },
      "source": [
        "Ouch only 24% of our vocabulary will have embeddings, making 21% of our data more or less useless. So lets have a look and start improving. For this we can easily have a look at the top oov words."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "de0a78175815413d204d9b7f70b5facba97a7b58",
        "execution": {
          "iopub.status.busy": "2021-06-01T20:07:13.924426Z",
          "iopub.execute_input": "2021-06-01T20:07:13.924690Z",
          "iopub.status.idle": "2021-06-01T20:07:13.941888Z",
          "shell.execute_reply.started": "2021-06-01T20:07:13.924638Z",
          "shell.execute_reply": "2021-06-01T20:07:13.940678Z"
        },
        "trusted": true,
        "id": "KmASX3kBfYby",
        "outputId": "459fa2e8-43cc-4768-cb3c-b1ec6ceae9a1"
      },
      "source": [
        "oov[:10]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('to', 403183),\n",
              " ('a', 402682),\n",
              " ('of', 330825),\n",
              " ('and', 251973),\n",
              " ('India?', 16384),\n",
              " ('it?', 12900),\n",
              " ('do?', 8753),\n",
              " ('life?', 7753),\n",
              " ('you?', 6295),\n",
              " ('me?', 6202)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_uuid": "dba213d3a9fefce81a3ab41e2ba95846f87da997",
        "id": "8vseah1GfYbz"
      },
      "source": [
        "On first place there is \"to\". Why? Simply because \"to\" was removed when the GoogleNews Embeddings were trained. We will fix this later, for now we take care about the splitting of punctuation as this also seems to be a Problem. But what do we do with the punctuation then - Do we want to delete or consider as a token? I would say: It depends. If the token has an embedding, keep it, if it doesn't we don't need it anymore. So lets check:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "69129cad1f08fda5912051d273db012f9adb081a",
        "execution": {
          "iopub.status.busy": "2021-06-01T20:07:13.943124Z",
          "iopub.execute_input": "2021-06-01T20:07:13.943409Z",
          "iopub.status.idle": "2021-06-01T20:07:13.955090Z",
          "shell.execute_reply.started": "2021-06-01T20:07:13.943354Z",
          "shell.execute_reply": "2021-06-01T20:07:13.954144Z"
        },
        "trusted": true,
        "id": "P6gWM7P5fYb0",
        "outputId": "45591496-4545-44d2-db17-53f7e633cc6e"
      },
      "source": [
        "'?' in embeddings_index"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "63deed2445710aef37e504a4d252b5ef02598f21",
        "execution": {
          "iopub.status.busy": "2021-06-01T20:07:13.957629Z",
          "iopub.execute_input": "2021-06-01T20:07:13.957888Z",
          "iopub.status.idle": "2021-06-01T20:07:13.966655Z",
          "shell.execute_reply.started": "2021-06-01T20:07:13.957838Z",
          "shell.execute_reply": "2021-06-01T20:07:13.965656Z"
        },
        "trusted": true,
        "id": "oCM-x9llfYb0",
        "outputId": "cafdbf10-9609-408f-e5b5-c0d2c552638f"
      },
      "source": [
        "'&' in embeddings_index"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_uuid": "361cbf32713d89b11d62c444cc87968460c454b8",
        "id": "ej9amEfyfYb1"
      },
      "source": [
        "Interesting. While \"&\" is in the Google News Embeddings, \"?\" is not. So we basically define a function that splits off \"&\" and removes other punctuation."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "afd570d1160b826a84c4c7af76950fd7a30e4471",
        "execution": {
          "iopub.status.busy": "2021-06-01T20:07:13.967859Z",
          "iopub.execute_input": "2021-06-01T20:07:13.968155Z",
          "iopub.status.idle": "2021-06-01T20:07:13.975775Z",
          "shell.execute_reply.started": "2021-06-01T20:07:13.968081Z",
          "shell.execute_reply": "2021-06-01T20:07:13.974936Z"
        },
        "trusted": true,
        "id": "HzC0GOEBfYb1"
      },
      "source": [
        "def clean_text(x):\n",
        "\n",
        "    x = str(x)\n",
        "    for punct in \"/-'\":\n",
        "        x = x.replace(punct, ' ')\n",
        "    for punct in '&':\n",
        "        x = x.replace(punct, f' {punct} ')\n",
        "    for punct in '?!.,\"#$%\\'()*+-/:;<=>@[\\\\]^_`{|}~' + '“”’':\n",
        "        x = x.replace(punct, '')\n",
        "    return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "b47c945e6f02c2a9f72aedd72da4681695cb20dd",
        "execution": {
          "iopub.status.busy": "2021-06-01T20:07:13.976899Z",
          "iopub.execute_input": "2021-06-01T20:07:13.977169Z",
          "iopub.status.idle": "2021-06-01T20:07:41.300119Z",
          "shell.execute_reply.started": "2021-06-01T20:07:13.977122Z",
          "shell.execute_reply": "2021-06-01T20:07:41.299333Z"
        },
        "trusted": true,
        "id": "SSpKpIPvfYb2",
        "outputId": "a14448c1-2255-4996-ab79-ac7d88d62e9a"
      },
      "source": [
        "train[\"question_text\"] = train[\"question_text\"].progress_apply(lambda x: clean_text(x))\n",
        "sentences = train[\"question_text\"].apply(lambda x: x.split())\n",
        "vocab = build_vocab(sentences)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 1306122/1306122 [00:16<00:00, 80199.06it/s]\n",
            "100%|██████████| 1306122/1306122 [00:05<00:00, 229140.37it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "9f90189a592e93f563d84d68a02ff48cc08315c0",
        "execution": {
          "iopub.status.busy": "2021-06-01T20:07:41.301193Z",
          "iopub.execute_input": "2021-06-01T20:07:41.301415Z",
          "iopub.status.idle": "2021-06-01T20:07:42.675729Z",
          "shell.execute_reply.started": "2021-06-01T20:07:41.301375Z",
          "shell.execute_reply": "2021-06-01T20:07:42.674496Z"
        },
        "trusted": true,
        "id": "LR_KU9N5fYb2",
        "outputId": "4ced8a14-1f6a-412c-953b-878e6c9494b3"
      },
      "source": [
        "oov = check_coverage(vocab,embeddings_index)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 253623/253623 [00:01<00:00, 241230.11it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Found embeddings for 57.38% of vocab\n",
            "Found embeddings for  89.99% of all text\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_uuid": "a06bdc24e539ea6d3fd17afd637c978fcaf36e7f",
        "id": "LPAbS_BkfYb3"
      },
      "source": [
        "Nice! We were able to increase our embeddings ratio from 24% to 57% by just handling punctiation. Ok lets check on thos oov words."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "5dff2b2ed016358b734b49e4d23d22cce746f43a",
        "execution": {
          "iopub.status.busy": "2021-06-01T20:07:42.677176Z",
          "iopub.execute_input": "2021-06-01T20:07:42.677511Z",
          "iopub.status.idle": "2021-06-01T20:07:42.684501Z",
          "shell.execute_reply.started": "2021-06-01T20:07:42.677445Z",
          "shell.execute_reply": "2021-06-01T20:07:42.683516Z"
        },
        "trusted": true,
        "id": "ZsPRd7NWfYb3",
        "outputId": "6ad692db-14b2-458d-e666-efd732917409"
      },
      "source": [
        "oov[:10]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('to', 406298),\n",
              " ('a', 403852),\n",
              " ('of', 332964),\n",
              " ('and', 254081),\n",
              " ('2017', 8781),\n",
              " ('2018', 7373),\n",
              " ('10', 6642),\n",
              " ('12', 3694),\n",
              " ('20', 2942),\n",
              " ('100', 2883)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_uuid": "55f7d6d8960ec03f0cf73e7e97d317065bf940dd",
        "id": "lFcWsOSqfYb4"
      },
      "source": [
        "Hmm seems like numbers also are a problem. Lets check the top 10 embeddings to get a clue."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "385ba7b4747ca28e1fea5d25c6a6edbeb9532cc6",
        "execution": {
          "iopub.status.busy": "2021-06-01T20:07:42.686084Z",
          "iopub.execute_input": "2021-06-01T20:07:42.686418Z",
          "iopub.status.idle": "2021-06-01T20:07:42.697326Z",
          "shell.execute_reply.started": "2021-06-01T20:07:42.686355Z",
          "shell.execute_reply": "2021-06-01T20:07:42.696044Z"
        },
        "trusted": true,
        "id": "g0Qw1JvJfYb4",
        "outputId": "d283fb21-fd5c-4c6e-ffc1-278223c80182"
      },
      "source": [
        "for i in range(10):\n",
        "    print(embeddings_index.index2entity[i])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "</s>\n",
            "in\n",
            "for\n",
            "that\n",
            "is\n",
            "on\n",
            "##\n",
            "The\n",
            "with\n",
            "said\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_uuid": "c2340ec62a0f679ffffe94bfafc323ecf517f4c9",
        "id": "NhJaiKAJfYb5"
      },
      "source": [
        "hmm why is \"##\" in there? Simply because as a reprocessing all numbers bigger tha 9 have been replaced by hashs. I.e. 15 becomes ## while 123 becomes ### or 15.80€ becomes ##.##€. So lets mimic this preprocessing step to further improve our embeddings coverage"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "bbc48ed45237a1096e29fac87c52d258b38fa1ee",
        "execution": {
          "iopub.status.busy": "2021-06-01T20:07:42.698506Z",
          "iopub.execute_input": "2021-06-01T20:07:42.698783Z",
          "iopub.status.idle": "2021-06-01T20:07:42.706199Z",
          "shell.execute_reply.started": "2021-06-01T20:07:42.698734Z",
          "shell.execute_reply": "2021-06-01T20:07:42.705192Z"
        },
        "trusted": true,
        "id": "N5FMDB9TfYb5"
      },
      "source": [
        "import re\n",
        "\n",
        "def clean_numbers(x):\n",
        "\n",
        "    x = re.sub('[0-9]{5,}', '#####', x)\n",
        "    x = re.sub('[0-9]{4}', '####', x)\n",
        "    x = re.sub('[0-9]{3}', '###', x)\n",
        "    x = re.sub('[0-9]{2}', '##', x)\n",
        "    return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "48da9d68b5d8911247a17a927649d33877570e0e",
        "execution": {
          "iopub.status.busy": "2021-06-01T20:07:42.707474Z",
          "iopub.execute_input": "2021-06-01T20:07:42.707800Z",
          "iopub.status.idle": "2021-06-01T20:08:21.098903Z",
          "shell.execute_reply.started": "2021-06-01T20:07:42.707737Z",
          "shell.execute_reply": "2021-06-01T20:08:21.097721Z"
        },
        "trusted": true,
        "id": "bwLiDERKfYb5",
        "outputId": "c9e49f8b-8578-4338-b9f1-67f3b059295a"
      },
      "source": [
        "train[\"question_text\"] = train[\"question_text\"].progress_apply(lambda x: clean_numbers(x))\n",
        "sentences = train[\"question_text\"].progress_apply(lambda x: x.split())\n",
        "vocab = build_vocab(sentences)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 1306122/1306122 [00:25<00:00, 50585.11it/s]\n",
            "100%|██████████| 1306122/1306122 [00:06<00:00, 216208.11it/s]\n",
            "100%|██████████| 1306122/1306122 [00:05<00:00, 219533.84it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "fb6a821cfdb49be15023fe4579c063394eaedbb9",
        "execution": {
          "iopub.status.busy": "2021-06-01T20:08:21.100492Z",
          "iopub.execute_input": "2021-06-01T20:08:21.100801Z",
          "iopub.status.idle": "2021-06-01T20:08:22.634444Z",
          "shell.execute_reply.started": "2021-06-01T20:08:21.100753Z",
          "shell.execute_reply": "2021-06-01T20:08:22.633676Z"
        },
        "trusted": true,
        "id": "QZjl3rF7fYb6",
        "outputId": "05069391-f2ce-463e-b9fb-6c93ee3ca3ba"
      },
      "source": [
        "oov = check_coverage(vocab,embeddings_index)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 242997/242997 [00:01<00:00, 195282.14it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Found embeddings for 60.41% of vocab\n",
            "Found embeddings for  90.75% of all text\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_uuid": "38618cca73324e598a8610c2ac8648e6aa7eb42b",
        "id": "dLna8BXqfYb7"
      },
      "source": [
        "Nice! Another 3% increase. Now as much as with handling the puntuation, but every bit helps. Lets check the oov words"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "14638ae1defa12014ed7b6be63f3a3bbebb9ed3e",
        "execution": {
          "iopub.status.busy": "2021-06-01T20:08:22.638027Z",
          "iopub.execute_input": "2021-06-01T20:08:22.638291Z",
          "iopub.status.idle": "2021-06-01T20:08:22.647499Z",
          "shell.execute_reply.started": "2021-06-01T20:08:22.638249Z",
          "shell.execute_reply": "2021-06-01T20:08:22.646724Z"
        },
        "trusted": true,
        "id": "nv4s6s_6fYb7",
        "outputId": "8444d615-a1b4-4085-8886-4dd7f6c7f65c"
      },
      "source": [
        "oov[:20]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('to', 406298),\n",
              " ('a', 403852),\n",
              " ('of', 332964),\n",
              " ('and', 254081),\n",
              " ('favourite', 1247),\n",
              " ('bitcoin', 987),\n",
              " ('colour', 976),\n",
              " ('doesnt', 918),\n",
              " ('centre', 886),\n",
              " ('Quorans', 858),\n",
              " ('cryptocurrency', 822),\n",
              " ('Snapchat', 807),\n",
              " ('travelling', 705),\n",
              " ('counselling', 634),\n",
              " ('btech', 632),\n",
              " ('didnt', 600),\n",
              " ('Brexit', 493),\n",
              " ('cryptocurrencies', 481),\n",
              " ('blockchain', 474),\n",
              " ('behaviour', 468)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_uuid": "17ca5651a141e21572e4a5abb23a7b368b5337ba",
        "id": "A0jm8vJrfYb8"
      },
      "source": [
        "Ok now we  take care of common misspellings when using american/ british vocab and replacing a few \"modern\" words with \"social media\" for this task I use a multi regex script I found some time ago on stack overflow. Additionally we will simply remove the words \"a\",\"to\",\"and\" and \"of\" since those have obviously been downsampled when training the GoogleNews Embeddings. \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "f1c3084cd7503c9148b681de897e0d38d7a90741",
        "execution": {
          "iopub.status.busy": "2021-06-01T20:08:22.648696Z",
          "iopub.execute_input": "2021-06-01T20:08:22.648911Z",
          "iopub.status.idle": "2021-06-01T20:08:22.662948Z",
          "shell.execute_reply.started": "2021-06-01T20:08:22.648878Z",
          "shell.execute_reply": "2021-06-01T20:08:22.661884Z"
        },
        "trusted": true,
        "id": "5KukJfiEfYb8"
      },
      "source": [
        "def _get_mispell(mispell_dict):\n",
        "    mispell_re = re.compile('(%s)' % '|'.join(mispell_dict.keys()))\n",
        "    return mispell_dict, mispell_re\n",
        "\n",
        "\n",
        "mispell_dict = {'colour':'color',\n",
        "                'centre':'center',\n",
        "                'didnt':'did not',\n",
        "                'doesnt':'does not',\n",
        "                'isnt':'is not',\n",
        "                'shouldnt':'should not',\n",
        "                'favourite':'favorite',\n",
        "                'travelling':'traveling',\n",
        "                'counselling':'counseling',\n",
        "                'theatre':'theater',\n",
        "                'cancelled':'canceled',\n",
        "                'labour':'labor',\n",
        "                'organisation':'organization',\n",
        "                'wwii':'world war 2',\n",
        "                'citicise':'criticize',\n",
        "                'instagram': 'social medium',\n",
        "                'whatsapp': 'social medium',\n",
        "                'snapchat': 'social medium'\n",
        "\n",
        "                }\n",
        "mispellings, mispellings_re = _get_mispell(mispell_dict)\n",
        "\n",
        "def replace_typical_misspell(text):\n",
        "    def replace(match):\n",
        "        return mispellings[match.group(0)]\n",
        "\n",
        "    return mispellings_re.sub(replace, text)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "c887a0a6f7498724a2c377e9e29fac683ea3a59b",
        "execution": {
          "iopub.status.busy": "2021-06-01T21:19:21.184941Z",
          "iopub.execute_input": "2021-06-01T21:19:21.185281Z",
          "iopub.status.idle": "2021-06-01T21:19:48.787143Z",
          "shell.execute_reply.started": "2021-06-01T21:19:21.185230Z",
          "shell.execute_reply": "2021-06-01T21:19:48.786290Z"
        },
        "trusted": true,
        "id": "Bg_6oKhyfYb9",
        "outputId": "38ef8660-2a34-4cb4-c99a-611d2cf60c1e"
      },
      "source": [
        "train[\"question_text\"] = train[\"question_text\"].progress_apply(lambda x: replace_typical_misspell(x))\n",
        "sentences = train[\"question_text\"].progress_apply(lambda x: x.split())\n",
        "to_remove = ['a','to','of','and']\n",
        "sentences = [[word for word in sentence if not word in to_remove] for sentence in tqdm(sentences)]\n",
        "vocab = build_vocab(sentences)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 1306122/1306122 [00:09<00:00, 143147.53it/s]\n",
            "100%|██████████| 1306122/1306122 [00:06<00:00, 213831.45it/s]\n",
            "100%|██████████| 1306122/1306122 [00:06<00:00, 214454.78it/s]\n",
            "100%|██████████| 1306122/1306122 [00:05<00:00, 240682.51it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "63aba43671245f1ebc87540a8bd49a174791c378",
        "execution": {
          "iopub.status.busy": "2021-06-01T21:19:48.788298Z",
          "iopub.execute_input": "2021-06-01T21:19:48.788503Z",
          "iopub.status.idle": "2021-06-01T21:19:50.123290Z",
          "shell.execute_reply.started": "2021-06-01T21:19:48.788466Z",
          "shell.execute_reply": "2021-06-01T21:19:50.122284Z"
        },
        "trusted": true,
        "id": "4ha6PwkAfYb-",
        "outputId": "b69704fe-bb50-468b-f338-18e074793368"
      },
      "source": [
        "oov = check_coverage(vocab,embeddings_index)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 242935/242935 [00:01<00:00, 203938.67it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Found embeddings for 60.43% of vocab\n",
            "Found embeddings for  98.96% of all text\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_uuid": "a5543990c3d10f9c77d58840a66bbcad11f233b5",
        "id": "tWrjNjHBfYb_"
      },
      "source": [
        "We see that although we improved on the amount of embeddings found for all our text from 89% to 99%. Lets check the oov words again "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "21f6da9413c717da789f1068387ac83e3bfd85ae",
        "execution": {
          "iopub.status.busy": "2021-06-01T21:19:50.124409Z",
          "iopub.execute_input": "2021-06-01T21:19:50.124673Z",
          "iopub.status.idle": "2021-06-01T21:19:50.130957Z",
          "shell.execute_reply.started": "2021-06-01T21:19:50.124621Z",
          "shell.execute_reply": "2021-06-01T21:19:50.129975Z"
        },
        "trusted": true,
        "id": "Q5FOz5DxfYb_",
        "outputId": "1fd60c3d-0bc5-4d3e-95aa-df320679bd44"
      },
      "source": [
        "oov[:20]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('bitcoin', 987),\n",
              " ('Quorans', 858),\n",
              " ('cryptocurrency', 822),\n",
              " ('Snapchat', 807),\n",
              " ('btech', 632),\n",
              " ('Brexit', 493),\n",
              " ('cryptocurrencies', 481),\n",
              " ('blockchain', 474),\n",
              " ('behaviour', 468),\n",
              " ('upvotes', 432),\n",
              " ('programme', 402),\n",
              " ('Redmi', 379),\n",
              " ('realise', 371),\n",
              " ('defence', 364),\n",
              " ('KVPY', 349),\n",
              " ('Paytm', 334),\n",
              " ('grey', 299),\n",
              " ('mtech', 281),\n",
              " ('Btech', 262),\n",
              " ('bitcoins', 254)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 164
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_uuid": "fe32acac0c1280d58ef66ac1611f63bbb98f0aec",
        "id": "AUM5wnkdfYcA"
      },
      "source": [
        "Looks good. No obvious oov words there we could quickly fix.\n",
        "Thank you for reading and happy kaggling"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MUlfmAS4fYcA"
      },
      "source": [
        "This is my own code from this line."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-06-01T21:19:50.132521Z",
          "iopub.execute_input": "2021-06-01T21:19:50.132771Z",
          "iopub.status.idle": "2021-06-01T21:19:50.141268Z",
          "shell.execute_reply.started": "2021-06-01T21:19:50.132732Z",
          "shell.execute_reply": "2021-06-01T21:19:50.140470Z"
        },
        "trusted": true,
        "id": "sgJxEj7xfYcA"
      },
      "source": [
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-06-01T21:19:50.142973Z",
          "iopub.execute_input": "2021-06-01T21:19:50.143308Z",
          "iopub.status.idle": "2021-06-01T21:19:50.199908Z",
          "shell.execute_reply.started": "2021-06-01T21:19:50.143247Z",
          "shell.execute_reply": "2021-06-01T21:19:50.198961Z"
        },
        "trusted": true,
        "id": "ZZyUdMl3fYcB",
        "outputId": "d51b561a-6571-480c-8ef6-19d699fb5f64"
      },
      "source": [
        "len(train[train['target'] == 1]) / len(train) # 94 : 6"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.06187017751787352"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 166
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MixQx8r_fYcB"
      },
      "source": [
        "Build feature set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-06-01T21:19:50.201201Z",
          "iopub.execute_input": "2021-06-01T21:19:50.201528Z",
          "iopub.status.idle": "2021-06-01T21:19:50.206426Z",
          "shell.execute_reply.started": "2021-06-01T21:19:50.201467Z",
          "shell.execute_reply": "2021-06-01T21:19:50.205469Z"
        },
        "trusted": true,
        "id": "UaGmF1NHfYcC"
      },
      "source": [
        "feature_df = pd.DataFrame()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-06-01T21:19:50.207887Z",
          "iopub.execute_input": "2021-06-01T21:19:50.208212Z",
          "iopub.status.idle": "2021-06-01T21:19:51.393720Z",
          "shell.execute_reply.started": "2021-06-01T21:19:50.208141Z",
          "shell.execute_reply": "2021-06-01T21:19:51.392828Z"
        },
        "trusted": true,
        "id": "btp33ir0fYcC"
      },
      "source": [
        "num_words = [len(sentence) for sentence in sentences]\n",
        "feature_df['num_words'] = num_words"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-06-01T21:19:51.395109Z",
          "iopub.execute_input": "2021-06-01T21:19:51.395447Z",
          "iopub.status.idle": "2021-06-01T21:19:53.780989Z",
          "shell.execute_reply.started": "2021-06-01T21:19:51.395388Z",
          "shell.execute_reply": "2021-06-01T21:19:53.780129Z"
        },
        "trusted": true,
        "id": "k2siXmjUfYcC"
      },
      "source": [
        "num_capital_words = [len([word for word in sentence if word.isupper()]) for sentence in sentences]\n",
        "feature_df['num_capital_words'] = num_capital_words"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-06-01T21:19:53.782397Z",
          "iopub.execute_input": "2021-06-01T21:19:53.782764Z",
          "iopub.status.idle": "2021-06-01T21:19:54.139044Z",
          "shell.execute_reply.started": "2021-06-01T21:19:53.782705Z",
          "shell.execute_reply": "2021-06-01T21:19:54.138194Z"
        },
        "trusted": true,
        "id": "r9S6HYRhfYcD"
      },
      "source": [
        "ratio_capital_words = np.array(num_capital_words) / (np.array(num_words) + 1e-5)\n",
        "feature_df['ratio_capital_words'] = ratio_capital_words"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-06-01T21:19:54.140353Z",
          "iopub.execute_input": "2021-06-01T21:19:54.140689Z",
          "iopub.status.idle": "2021-06-01T21:24:35.611315Z",
          "shell.execute_reply.started": "2021-06-01T21:19:54.140620Z",
          "shell.execute_reply": "2021-06-01T21:24:35.610721Z"
        },
        "trusted": true,
        "id": "a58-QTXmfYcD",
        "outputId": "5d6dbc70-e304-47a0-def8-f883617e9f49"
      },
      "source": [
        "%%time\n",
        "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
        "\n",
        "sid = SentimentIntensityAnalyzer()\n",
        "\n",
        "train_text = train['question_text']\n",
        "polarity_score = [sid.polarity_scores(sentence)['compound'] for sentence in train_text]\n",
        "feature_df['polarity_score'] = polarity_score"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 4min 41s, sys: 33.8 ms, total: 4min 41s\n",
            "Wall time: 4min 41s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-06-01T21:25:15.830627Z",
          "iopub.execute_input": "2021-06-01T21:25:15.830927Z",
          "iopub.status.idle": "2021-06-01T21:25:16.519995Z",
          "shell.execute_reply.started": "2021-06-01T21:25:15.830888Z",
          "shell.execute_reply": "2021-06-01T21:25:16.519328Z"
        },
        "trusted": true,
        "id": "2wKs1QLkfYcH"
      },
      "source": [
        "len_sentence = [len(sentence) for sentence in train_text]\n",
        "feature_df['len_sentence'] = len_sentence"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-06-01T21:25:18.510526Z",
          "iopub.execute_input": "2021-06-01T21:25:18.510810Z",
          "iopub.status.idle": "2021-06-01T21:25:21.342753Z",
          "shell.execute_reply.started": "2021-06-01T21:25:18.510771Z",
          "shell.execute_reply": "2021-06-01T21:25:21.341692Z"
        },
        "trusted": true,
        "id": "-6WSUNeXfYcI"
      },
      "source": [
        "oov_words = {word for word, _ in oov}\n",
        "num_oov = [len([word for word in sentence if word in oov_words]) for sentence in sentences]\n",
        "feature_df['num_oov'] = num_oov"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-06-01T21:25:22.283579Z",
          "iopub.execute_input": "2021-06-01T21:25:22.283918Z",
          "iopub.status.idle": "2021-06-01T21:25:22.637548Z",
          "shell.execute_reply.started": "2021-06-01T21:25:22.283861Z",
          "shell.execute_reply": "2021-06-01T21:25:22.636547Z"
        },
        "trusted": true,
        "id": "7PHFuFHZfYcI"
      },
      "source": [
        "ratio_oov = np.array(num_oov) / (np.array(num_words) + 1e-5)\n",
        "feature_df['ratio_oov'] = ratio_oov"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-06-01T21:25:24.132477Z",
          "iopub.execute_input": "2021-06-01T21:25:24.132929Z",
          "iopub.status.idle": "2021-06-01T21:25:24.497830Z",
          "shell.execute_reply.started": "2021-06-01T21:25:24.132874Z",
          "shell.execute_reply": "2021-06-01T21:25:24.496921Z"
        },
        "trusted": true,
        "id": "KqzNrIBOfYcJ"
      },
      "source": [
        "ratio_words = np.array(num_words) / (np.array(len_sentence) + 1e-5)\n",
        "feature_df['ratio_words'] = ratio_words"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JfSXT7VAfYcJ"
      },
      "source": [
        "# Please add more features.."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-06-01T21:25:44.099359Z",
          "iopub.execute_input": "2021-06-01T21:25:44.099797Z",
          "iopub.status.idle": "2021-06-01T21:25:44.132622Z",
          "shell.execute_reply.started": "2021-06-01T21:25:44.099758Z",
          "shell.execute_reply": "2021-06-01T21:25:44.132057Z"
        },
        "trusted": true,
        "id": "fBocB9N8fYcK",
        "outputId": "a5c07dd7-8b29-4445-ebb1-778798b2b44f"
      },
      "source": [
        "feature_df['target'] = train['target']\n",
        "feature_df.head(n=10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   num_words  num_capital_words       ...        target  polarity_score\n",
              "0         12                  0       ...             0          0.0000\n",
              "1         14                  0       ...             0          0.6124\n",
              "2         10                  0       ...             0          0.0000\n",
              "3          9                  0       ...             0          0.0000\n",
              "4         13                  2       ...             0          0.0000\n",
              "5         10                  0       ...             0          0.0000\n",
              "6         18                  0       ...             0         -0.3182\n",
              "7         14                  1       ...             0         -0.3400\n",
              "8         16                  0       ...             0          0.0000\n",
              "9         42                  0       ...             0          0.4779\n",
              "\n",
              "[10 rows x 9 columns]"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>num_words</th>\n",
              "      <th>num_capital_words</th>\n",
              "      <th>ratio_capital_words</th>\n",
              "      <th>len_sentence</th>\n",
              "      <th>num_oov</th>\n",
              "      <th>ratio_oov</th>\n",
              "      <th>ratio_words</th>\n",
              "      <th>target</th>\n",
              "      <th>polarity_score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>12</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>71</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.169014</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>14</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>79</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.177215</td>\n",
              "      <td>0</td>\n",
              "      <td>0.6124</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>10</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>65</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.153846</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>9</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>56</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.160714</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>13</td>\n",
              "      <td>2</td>\n",
              "      <td>0.153846</td>\n",
              "      <td>76</td>\n",
              "      <td>3</td>\n",
              "      <td>0.230769</td>\n",
              "      <td>0.171053</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>10</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>70</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.142857</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>18</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>111</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.162162</td>\n",
              "      <td>0</td>\n",
              "      <td>-0.3182</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>14</td>\n",
              "      <td>1</td>\n",
              "      <td>0.071429</td>\n",
              "      <td>67</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.208955</td>\n",
              "      <td>0</td>\n",
              "      <td>-0.3400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>16</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>99</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.161616</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>42</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>243</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.172839</td>\n",
              "      <td>0</td>\n",
              "      <td>0.4779</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 179
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-06-01T20:51:30.238491Z",
          "iopub.execute_input": "2021-06-01T20:51:30.238788Z",
          "iopub.status.idle": "2021-06-01T20:51:30.244234Z",
          "shell.execute_reply.started": "2021-06-01T20:51:30.238751Z",
          "shell.execute_reply": "2021-06-01T20:51:30.243035Z"
        },
        "trusted": true,
        "id": "1pL3qtnqfYcL"
      },
      "source": [
        "from sklearn.preprocessing import RobustScaler\n",
        "\n",
        "def feature_scaling(df):\n",
        "    target = df.pop('target') # We will not consider target\n",
        "    scaler = RobustScaler()\n",
        "    scaler.fit(df)\n",
        "    df = pd.DataFrame(scaler.transform(df), columns=df.columns, index=list(df.index.values))\n",
        "    df['target'] = target\n",
        "    return df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-06-01T20:51:38.891156Z",
          "iopub.execute_input": "2021-06-01T20:51:38.891799Z",
          "iopub.status.idle": "2021-06-01T20:51:38.898606Z",
          "shell.execute_reply.started": "2021-06-01T20:51:38.891726Z",
          "shell.execute_reply": "2021-06-01T20:51:38.897206Z"
        },
        "trusted": true,
        "id": "mI7JXtDlfYcL"
      },
      "source": [
        "from sklearn.impute import SimpleImputer\n",
        "\n",
        "def missing_data_handling(df):\n",
        "    target = df.pop('target') # We will not consider target\n",
        "    imp = SimpleImputer(strategy='mean')\n",
        "    imp.fit(df)\n",
        "    df = pd.DataFrame(imp.transform(df), columns=df.columns, index=list(df.index.values))\n",
        "    df['target'] = target\n",
        "    return df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-06-01T20:51:33.712271Z",
          "iopub.execute_input": "2021-06-01T20:51:33.712557Z",
          "iopub.status.idle": "2021-06-01T20:51:33.718151Z",
          "shell.execute_reply.started": "2021-06-01T20:51:33.712512Z",
          "shell.execute_reply": "2021-06-01T20:51:33.717201Z"
        },
        "trusted": true,
        "id": "vGSrX8u7fYcM"
      },
      "source": [
        "def outlier_handling(df):\n",
        "    target = df.pop('target') # We will not consider target\n",
        "    for column in df.columns:\n",
        "        Q1 = np.percentile(df[column], 25)\n",
        "        Q3 = np.percentile(df[column], 75)\n",
        "        IQR = Q3 - Q1\n",
        "        df = df[(df[column] <= Q3 + 1.5 * IQR) & (df[column] >= Q1 - 1.5 * IQR)]\n",
        "    df['target'] = target\n",
        "    return df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-06-01T21:26:00.810629Z",
          "iopub.execute_input": "2021-06-01T21:26:00.811183Z",
          "iopub.status.idle": "2021-06-01T21:26:02.598955Z",
          "shell.execute_reply.started": "2021-06-01T21:26:00.811115Z",
          "shell.execute_reply": "2021-06-01T21:26:02.598294Z"
        },
        "trusted": true,
        "id": "FkXYAPqlfYcM",
        "outputId": "77cf181f-64e9-48dc-f005-a23e3fddddcc"
      },
      "source": [
        "# feature_df = outlier_handling(feature_df)\n",
        "feature_df = feature_scaling(feature_df)\n",
        "feature_df = missing_data_handling(feature_df)\n",
        "feature_df.head(n=10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   num_words  num_capital_words   ...    polarity_score  target\n",
              "0   0.333333                0.0   ...          0.000000       0\n",
              "1   0.666667                0.0   ...          1.695460       0\n",
              "2   0.000000                0.0   ...          0.000000       0\n",
              "3  -0.166667                0.0   ...          0.000000       0\n",
              "4   0.500000                2.0   ...          0.000000       0\n",
              "5   0.000000                0.0   ...          0.000000       0\n",
              "6   1.333333                0.0   ...         -0.880952       0\n",
              "7   0.666667                1.0   ...         -0.941307       0\n",
              "8   1.000000                0.0   ...          0.000000       0\n",
              "9   5.333333                0.0   ...          1.323090       0\n",
              "\n",
              "[10 rows x 9 columns]"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>num_words</th>\n",
              "      <th>num_capital_words</th>\n",
              "      <th>ratio_capital_words</th>\n",
              "      <th>len_sentence</th>\n",
              "      <th>num_oov</th>\n",
              "      <th>ratio_oov</th>\n",
              "      <th>ratio_words</th>\n",
              "      <th>polarity_score</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.300</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-0.144277</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.500</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.097251</td>\n",
              "      <td>1.695460</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.150</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-0.590983</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-0.166667</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-0.075</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-0.388712</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.500000</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.153846</td>\n",
              "      <td>0.425</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0.230769</td>\n",
              "      <td>-0.084241</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.275</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-0.914617</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>1.333333</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.300</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-0.346071</td>\n",
              "      <td>-0.880952</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>0.666667</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.200</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.032016</td>\n",
              "      <td>-0.941307</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-0.362151</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>5.333333</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>4.600</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-0.031615</td>\n",
              "      <td>1.323090</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 180
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-06-01T21:24:35.911734Z",
          "iopub.status.idle": "2021-06-01T21:24:35.912226Z"
        },
        "trusted": true,
        "id": "9KtnkzyefYcN"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "train_df, test_df = train_test_split(feature_df, test_size=0.2)\n",
        "y_train = train_df['target']\n",
        "X_train = train_df.drop(['target'], axis=1)\n",
        "y_test = test_df['target']\n",
        "X_test = test_df.drop(['target'], axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-06-01T20:55:03.227997Z",
          "iopub.execute_input": "2021-06-01T20:55:03.228409Z",
          "iopub.status.idle": "2021-06-01T20:55:03.234260Z",
          "shell.execute_reply.started": "2021-06-01T20:55:03.228320Z",
          "shell.execute_reply": "2021-06-01T20:55:03.233172Z"
        },
        "trusted": true,
        "id": "1GQCDiNLfYcO"
      },
      "source": [
        "from sklearn.metrics import r2_score\n",
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "def adj_r2(X, y):\n",
        "    reg = LinearRegression()\n",
        "    reg.fit(X, y)\n",
        "    y_pred = reg.predict(X)\n",
        "    \n",
        "    r2 = r2_score(y, y_pred)\n",
        "    n = len(y)\n",
        "    p = len(X.columns)\n",
        "    adjusted_r2 = 1 - (1 - r2) * (n - 1) / (n - p - 1)\n",
        "    \n",
        "    return adjusted_r2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-06-01T21:28:06.667486Z",
          "iopub.execute_input": "2021-06-01T21:28:06.668028Z",
          "iopub.status.idle": "2021-06-01T21:28:06.674931Z",
          "shell.execute_reply.started": "2021-06-01T21:28:06.667980Z",
          "shell.execute_reply": "2021-06-01T21:28:06.674346Z"
        },
        "trusted": true,
        "id": "Tpa_2dPIfYcO"
      },
      "source": [
        "from copy import deepcopy\n",
        "\n",
        "def forward_selection(data, target, n_features):\n",
        "    remaining_features = data.columns.tolist()\n",
        "    selected_features = []\n",
        "    best_score = 0.\n",
        "    \n",
        "    prev_features = [] # selected features of previous step\n",
        "    for _ in range(n_features):\n",
        "        cur_best_score = 0. # best score of current step\n",
        "        cur_best_feature = '' # best feature to select in current step\n",
        "        for feature in remaining_features:\n",
        "            \n",
        "            cur_features = prev_features + [feature]\n",
        "            X = data[cur_features]\n",
        "            \n",
        "            adjusted_r2 = adj_r2(X, target)\n",
        "            # print(adjusted_r2)\n",
        "            if adjusted_r2 >= cur_best_score:\n",
        "                cur_best_score = adjusted_r2\n",
        "                cur_best_feature = feature\n",
        "\n",
        "    if cur_best_feature:\n",
        "        prev_features.append(cur_best_feature)\n",
        "        remaining_features.remove(cur_best_feature)\n",
        "        \n",
        "        if cur_best_score > best_score:\n",
        "            selected_features = deepcopy(prev_features)\n",
        "\n",
        "\n",
        "    return selected_features"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-06-01T21:28:08.738656Z",
          "iopub.execute_input": "2021-06-01T21:28:08.739243Z",
          "iopub.status.idle": "2021-06-01T21:28:10.046091Z",
          "shell.execute_reply.started": "2021-06-01T21:28:08.739165Z",
          "shell.execute_reply": "2021-06-01T21:28:10.045172Z"
        },
        "trusted": true,
        "id": "DjTMakq-fYcP",
        "outputId": "7ab77494-20ac-45ae-ae9d-d74d8583d928"
      },
      "source": [
        "fs = forward_selection(X_train, y_train, 8)\n",
        "print(fs)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['len_sentence']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-06-01T21:28:17.568392Z",
          "iopub.execute_input": "2021-06-01T21:28:17.570380Z",
          "iopub.status.idle": "2021-06-01T21:28:17.574963Z",
          "shell.execute_reply.started": "2021-06-01T21:28:17.570307Z",
          "shell.execute_reply": "2021-06-01T21:28:17.574327Z"
        },
        "trusted": true,
        "id": "E6fRKQx4fYcQ"
      },
      "source": [
        "from sklearn.metrics import classification_report, f1_score\n",
        "from sklearn.model_selection import GridSearchCV"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-06-01T21:28:19.713778Z",
          "iopub.execute_input": "2021-06-01T21:28:19.714220Z",
          "iopub.status.idle": "2021-06-01T21:28:20.104046Z",
          "shell.execute_reply.started": "2021-06-01T21:28:19.714166Z",
          "shell.execute_reply": "2021-06-01T21:28:20.103083Z"
        },
        "trusted": true,
        "id": "nU8m9AdgfYcR",
        "outputId": "8501c7db-bfa3-4278-b8f9-80f67cda29a7"
      },
      "source": [
        "# Naive Bayes\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "\n",
        "nb = GaussianNB()\n",
        "nb.fit(X_train, y_train)\n",
        "y_pred = nb.predict(X_test)\n",
        "print(classification_report(y_test, y_pred))\n",
        "print(f1_score(y_test, y_pred))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.94      0.97      0.96    245227\n",
            "           1       0.20      0.10      0.13     15998\n",
            "\n",
            "   micro avg       0.92      0.92      0.92    261225\n",
            "   macro avg       0.57      0.54      0.55    261225\n",
            "weighted avg       0.90      0.92      0.91    261225\n",
            "\n",
            "0.13319301199747421\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-06-01T21:28:30.749693Z",
          "iopub.execute_input": "2021-06-01T21:28:30.750121Z"
        },
        "trusted": true,
        "id": "4ttlSyLHfYcR",
        "outputId": "1fa5f319-bd2a-42da-ba07-8c101a46579c"
      },
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.svm import SVC\n",
        "\n",
        "grid_params = {\n",
        "    'C': [0.001, 0.01, 0.1, 1, 10, 100],\n",
        "    'gamma': [0.001, 0.01, 0.1, 1, 10, 100]\n",
        "}\n",
        "gs = GridSearchCV(SVC(), grid_params, verbose=2)\n",
        "gs.fit(X_train, y_train)\n",
        "\n",
        "best_params = gs.best_params_\n",
        "print(gs.best_params_)\n",
        "\n",
        "svm = SVC(**best_params)\n",
        "svm.fit(X_train, y_train)\n",
        "y_pred = svm.predict(X_test)\n",
        "print(classification_report(y_test, y_pred))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/opt/conda/lib/python3.6/site-packages/sklearn/model_selection/_split.py:1943: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
            "  warnings.warn(CV_WARNING, FutureWarning)\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Fitting 3 folds for each of 36 candidates, totalling 108 fits\n",
            "[CV] C=0.001, gamma=0.001 ............................................\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ixgWyjCjfYcS"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
