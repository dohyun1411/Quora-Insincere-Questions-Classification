{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "BiLSTM.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "mount_file_id": "1Z2M2KThOqKhMwVCXnCxnpjLLwBHH4inj",
      "authorship_tag": "ABX9TyNPFE6b0zIPUhhcLBU4phRP",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "aefbcff2855a4cc5812ca5ad394966d3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_53e9f1b039a54a048d13ca34debacd0a",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_bf4fd6c044ce418db1ad61f1285180da",
              "IPY_MODEL_c7bdf62068364e37adbb2eda941fae1a"
            ]
          }
        },
        "53e9f1b039a54a048d13ca34debacd0a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "bf4fd6c044ce418db1ad61f1285180da": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_3c20ceda51ea4fabb1bf7a7f657ec569",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 1306122,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1306122,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_8f0bc28026cc47dbada75c015927b933"
          }
        },
        "c7bdf62068364e37adbb2eda941fae1a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_43c173ffbfd34cabbaef8ee6a8097f32",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 1306122/1306122 [05:35&lt;00:00, 3894.44it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_16f577a3b29647f4b35c87aae3c208e5"
          }
        },
        "3c20ceda51ea4fabb1bf7a7f657ec569": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "8f0bc28026cc47dbada75c015927b933": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "43c173ffbfd34cabbaef8ee6a8097f32": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "16f577a3b29647f4b35c87aae3c208e5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "0fab704f3f17461b9c4edbcec41eaedb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_ad48d74b86b1425cb30092c911f252bf",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_31187127d60a442a96d55db35e69a650",
              "IPY_MODEL_1ae6c2ee05914a5fa25f13120b21d794"
            ]
          }
        },
        "ad48d74b86b1425cb30092c911f252bf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "31187127d60a442a96d55db35e69a650": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_4fe29aa624084394af32e57d92499731",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 375806,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 375806,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_8f7710ad17d94e079fd14fc1f49702ee"
          }
        },
        "1ae6c2ee05914a5fa25f13120b21d794": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_8f73b7a3e13447a883cb49daec8b5679",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 375806/375806 [00:13&lt;00:00, 27389.19it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_479b7a1b9a924193b11f3444d38a4b1f"
          }
        },
        "4fe29aa624084394af32e57d92499731": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "8f7710ad17d94e079fd14fc1f49702ee": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "8f73b7a3e13447a883cb49daec8b5679": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "479b7a1b9a924193b11f3444d38a4b1f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "844c4f88cb8b4103bcce60e1a47fc85f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_5289cbb9cee44a3ca9172e90a0a9c842",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_33e28a374d9e452794ba2e6f558a8071",
              "IPY_MODEL_eadb51d5b65445d4aa99a22763d45181"
            ]
          }
        },
        "5289cbb9cee44a3ca9172e90a0a9c842": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "33e28a374d9e452794ba2e6f558a8071": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_8499568c7ef044b584ecae709d0dfca8",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 345785,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 345785,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_85bd9d1f44c54a97803d69e88d87bad7"
          }
        },
        "eadb51d5b65445d4aa99a22763d45181": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_ae0380223c294744977e1f6946c04dda",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 345785/345785 [00:05&lt;00:00, 58955.37it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_dea789c5fa3548839384b26bc2d5a8a7"
          }
        },
        "8499568c7ef044b584ecae709d0dfca8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "85bd9d1f44c54a97803d69e88d87bad7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "ae0380223c294744977e1f6946c04dda": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "dea789c5fa3548839384b26bc2d5a8a7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e92864da1bff40dfa49182e6abbe3997": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_562ae141f82540aeaa11daf1c32fe347",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_dd69cc7940ca4c4c8a6b5340d1f82083",
              "IPY_MODEL_fb73ab7a2a09443f9e02a8639439c6c5"
            ]
          }
        },
        "562ae141f82540aeaa11daf1c32fe347": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "dd69cc7940ca4c4c8a6b5340d1f82083": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_c06f8a1a124243eca4eefd29549e3959",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 345785,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 345785,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_38bcbf9bed274a1c80ae081059d36cba"
          }
        },
        "fb73ab7a2a09443f9e02a8639439c6c5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_b7fb8c65e1d4494d99eb54883c6a16bb",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 345785/345785 [00:04&lt;00:00, 71810.96it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_4818ae0098634bf592463b1e12918178"
          }
        },
        "c06f8a1a124243eca4eefd29549e3959": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "38bcbf9bed274a1c80ae081059d36cba": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "b7fb8c65e1d4494d99eb54883c6a16bb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "4818ae0098634bf592463b1e12918178": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dohyun1411/Quora-Insincere-Questions-Classification/blob/preprocessing1/BiLSTM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MjG4VaNGNC_F",
        "outputId": "71d05840-a3af-4a46-daf2-8e0c1e7a8b5f"
      },
      "source": [
        "import re\n",
        "import gc\n",
        "import random\n",
        "import os\n",
        "\n",
        "from tqdm.auto import tqdm\n",
        "tqdm.pandas()\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from sklearn.model_selection import train_test_split, KFold, StratifiedKFold\n",
        "from sklearn.metrics import f1_score\n",
        "\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "from keras.layers import Dense, Input, CuDNNLSTM, Embedding, Dropout, Activation, CuDNNGRU, Conv1D\n",
        "from keras.layers import Bidirectional, GlobalMaxPool1D, GlobalMaxPooling1D, GlobalAveragePooling1D\n",
        "from keras.layers import Input, Embedding, Dense, Conv2D, MaxPool2D, concatenate\n",
        "from keras.layers import Reshape, Flatten, Concatenate, Dropout, SpatialDropout1D\n",
        "from keras.optimizers import Adam\n",
        "from keras.models import Model\n",
        "from keras.engine.topology import Layer\n",
        "from keras import initializers, regularizers, constraints, optimizers, layers\n",
        "\n",
        "from keras.layers import *\n",
        "from keras.models import *\n",
        "from keras import initializers, regularizers, constraints, optimizers, layers\n",
        "from keras.initializers import *\n",
        "from keras.optimizers import *\n",
        "import keras.backend as K\n",
        "from keras.callbacks import *\n",
        "import tensorflow as tf"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tqdm/std.py:658: FutureWarning: The Panel class is removed from pandas. Accessing it from the top-level namespace will also be removed in the next version\n",
            "  from pandas import Panel\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "seq4dn8WNkPd"
      },
      "source": [
        "Config"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n1YYJL-KNl6a"
      },
      "source": [
        "n_splits = 5\n",
        "input_path = '/content/drive/MyDrive/ColabNotebooks/QIQC/data'\n",
        "max_features = 120000 # None\n",
        "embed_size = 300\n",
        "maxlen = 70 # None\n",
        "batch_size = 512\n",
        "max_epoch = 5"
      ],
      "execution_count": 108,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VPjrREs66UgD"
      },
      "source": [
        "Load train and test data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w45w3ftY6WhC"
      },
      "source": [
        "train_path = os.path.join(input_path, 'train.csv')\n",
        "test_path = os.path.join(input_path, 'test.csv')\n",
        "\n",
        "train_df = pd.read_csv(train_path)\n",
        "test_df = pd.read_csv(test_path)"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D0ko9_3V6qRO"
      },
      "source": [
        "Tokenize"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tjUtD9vy6Woh"
      },
      "source": [
        "to_exclude = ''\n",
        "to_tokenize = puncts\n",
        "\n",
        "tokenizer = Tokenizer(filters=to_exclude, lower=False)"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xm9DColL6WrG"
      },
      "source": [
        "train_text = train_df[\"question_text\"].fillna(\"_na_\")\n",
        "test_text = test_df[\"question_text\"].fillna(\"_na_\")\n",
        "train_y = train_df['target'].values"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 117,
          "referenced_widgets": [
            "aefbcff2855a4cc5812ca5ad394966d3",
            "53e9f1b039a54a048d13ca34debacd0a",
            "bf4fd6c044ce418db1ad61f1285180da",
            "c7bdf62068364e37adbb2eda941fae1a",
            "3c20ceda51ea4fabb1bf7a7f657ec569",
            "8f0bc28026cc47dbada75c015927b933",
            "43c173ffbfd34cabbaef8ee6a8097f32",
            "16f577a3b29647f4b35c87aae3c208e5",
            "0fab704f3f17461b9c4edbcec41eaedb",
            "ad48d74b86b1425cb30092c911f252bf",
            "31187127d60a442a96d55db35e69a650",
            "1ae6c2ee05914a5fa25f13120b21d794",
            "4fe29aa624084394af32e57d92499731",
            "8f7710ad17d94e079fd14fc1f49702ee",
            "8f73b7a3e13447a883cb49daec8b5679",
            "479b7a1b9a924193b11f3444d38a4b1f"
          ]
        },
        "id": "wlpfmE7Y6pjF",
        "outputId": "4d3d9e24-7722-42fc-ba76-28235d92fb9a"
      },
      "source": [
        "train_text = train_text.progress_apply(lambda x: re.sub(r'(['+to_tokenize+'])', r' \\1', x)).values\n",
        "test_text = test_text.progress_apply(lambda x: re.sub(r'(['+to_tokenize+'])', r' \\1', x)).values"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "aefbcff2855a4cc5812ca5ad394966d3",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=1306122.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0fab704f3f17461b9c4edbcec41eaedb",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=375806.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CHY6XMyJ6pmt"
      },
      "source": [
        "text = list(train_text) + list(test_text)"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BDVp0_Lo65bf"
      },
      "source": [
        "tokenizer.fit_on_texts(text)\n",
        "word_index = tokenizer.word_index"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NpdI2Ic3_2RU"
      },
      "source": [
        "train_X = tokenizer.texts_to_sequences(train_text)\n",
        "test_X = tokenizer.texts_to_sequences(test_text)\n",
        "\n",
        "train_X = pad_sequences(train_X, maxlen=maxlen)\n",
        "test_X = pad_sequences(test_X, maxlen=maxlen)"
      ],
      "execution_count": 109,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yGfBuPzG85Ta"
      },
      "source": [
        "max_features = len(word_index) if max_features is None else max_features\n",
        "# maxlen = max({len(seq) for seq in train_X} | {len(seq) for seq in val_X} | {len(seq) for seq in test_X}) if maxlen is None else maxlen"
      ],
      "execution_count": 110,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "faLW2hAoM8_X"
      },
      "source": [
        "Load embedding"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N7uCdzyaM6Qh"
      },
      "source": [
        "import zipfile\n",
        "from gensim.models import KeyedVectors\n",
        "\n",
        "embeddings_path = os.path.join(input_path, 'embeddings.zip')\n",
        "\n",
        "glove = 'glove.840B.300d/glove.840B.300d.txt'\n",
        "wiki = 'wiki-news-300d-1M/wiki-news-300d-1M.vec'\n",
        "google = 'GoogleNews-vectors-negative300/GoogleNews-vectors-negative300.bin'\n",
        "para = 'paragram_300_sl999/paragram_300_sl999.txt'\n",
        "\n",
        "\n",
        "def load_embedding(embedding_name):\n",
        "\n",
        "    def get_coefs(word, *arr): return word, np.asarray(arr, dtype='float32')\n",
        "\n",
        "    with zipfile.ZipFile(embeddings_path) as embeddings_zip:\n",
        "\n",
        "        if embedding_name == google:\n",
        "            return KeyedVectors.load_word2vec_format(embeddings_zip.open(google), binary=True)\n",
        "\n",
        "        else:\n",
        "            embedding = []\n",
        "            for o in embeddings_zip.open(embedding_name):\n",
        "                try:\n",
        "                    if len(o.decode('utf-8')) > 100:\n",
        "                        embedding.append(get_coefs(*o.decode('utf-8').split(\" \")))\n",
        "                except:\n",
        "                    pass\n",
        "        \n",
        "        return dict(embedding)"
      ],
      "execution_count": 111,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cu0T-YHfOt0L"
      },
      "source": [
        "import nltk\n",
        "# nltk.download('wordnet')\n",
        "\n",
        "from nltk.stem import PorterStemmer\n",
        "from nltk.stem import LancasterStemmer\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "s = PorterStemmer()\n",
        "l = LancasterStemmer()\n",
        "n = WordNetLemmatizer()\n",
        "\n",
        "def is_in_emb(word, i, embedding, emb_matrix):\n",
        "\n",
        "    if word in embedding:\n",
        "        emb_matrix[i] = embedding[word]\n",
        "        return True\n",
        "    \n",
        "    tmp = word.lower()\n",
        "    if tmp in embedding:\n",
        "        emb_matrix[i] = embedding[tmp]\n",
        "        return True\n",
        "    \n",
        "    tmp = word.upper()\n",
        "    if tmp in embedding:\n",
        "        emb_matrix[i] = embedding[tmp]\n",
        "        return True\n",
        "\n",
        "    tmp = word.capitalize()\n",
        "    if tmp in embedding:\n",
        "        emb_matrix[i] = embedding[tmp]\n",
        "        return True\n",
        "\n",
        "    tmp = s.stem(word)\n",
        "    if tmp in embedding:\n",
        "        emb_matrix[i] = embedding[tmp]\n",
        "        return True\n",
        "    \n",
        "    tmp = l.stem(word)\n",
        "    if tmp in embedding:\n",
        "        emb_matrix[i] = embedding[tmp]\n",
        "        return True\n",
        "    \n",
        "    tmp = n.lemmatize(word)\n",
        "    if tmp in embedding:\n",
        "        emb_matrix[i] = embedding[tmp]\n",
        "        return True\n",
        "    \n",
        "    return False"
      ],
      "execution_count": 112,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wp2R6V811SHp"
      },
      "source": [
        "puncts = '´‘’“”…!#$%&()*+,-./:;<=>?@[\\]^_`{|}~\"' + \"'\""
      ],
      "execution_count": 113,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AaAoKuAoM6Lg"
      },
      "source": [
        "def load_emb_matrix(embedding_name):\n",
        "\n",
        "    embedding = load_embedding(embedding_name)\n",
        "    if embedding_name == glove: emb_mean, emb_std = -0.005838499, 0.48782197\n",
        "    if embedding_name == wiki: emb_mean, emb_std = -0.0033469985, 0.109855495\n",
        "    if embedding_name == google: emb_mean, emb_std = -0.003527845, 0.13315111\n",
        "    if embedding_name == para: emb_mean, emb_std = -0.0053248387, 0.49346521\n",
        "    emb_matrix = np.random.normal(emb_mean, emb_std, (max_features, embed_size))\n",
        "    for word, i in tqdm(word_index.items()):\n",
        "        i -= 1\n",
        "        assert i >= 0\n",
        "\n",
        "        if i >= max_features: continue\n",
        "\n",
        "        if is_in_emb(word, i, embedding, emb_matrix): continue\n",
        "\n",
        "        if embedding_name == google:\n",
        "\n",
        "            tmp = re.sub('[0-9]{5,}', '#####', word)\n",
        "            tmp = re.sub('[0-9]{4}', '####', tmp)\n",
        "            tmp = re.sub('[0-9]{3}', '###', tmp)\n",
        "            tmp = re.sub('[0-9]{2}', '##', tmp)\n",
        "            if is_in_emb(tmp, i, google_embedding, google_emb_matrix): continue\n",
        "\n",
        "            for punct in puncts:\n",
        "                tmp = tmp.replace(punct, '')\n",
        "            if is_in_emb(tmp, i, google_embedding, google_emb_matrix): continue\n",
        "\n",
        "        else:\n",
        "        \n",
        "            tmp = word\n",
        "            for punct in puncts:\n",
        "                tmp = tmp.replace(punct, '')\n",
        "            if is_in_emb(tmp, i, embedding, emb_matrix): continue\n",
        "\n",
        "            for num in '0123456789':\n",
        "                tmp = tmp.replace(num, '')\n",
        "            if is_in_emb(tmp, i, embedding, emb_matrix): continue\n",
        "    \n",
        "\n",
        "    del embedding\n",
        "    gc.collect()\n",
        "    return emb_matrix"
      ],
      "execution_count": 114,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104,
          "referenced_widgets": [
            "844c4f88cb8b4103bcce60e1a47fc85f",
            "5289cbb9cee44a3ca9172e90a0a9c842",
            "33e28a374d9e452794ba2e6f558a8071",
            "eadb51d5b65445d4aa99a22763d45181",
            "8499568c7ef044b584ecae709d0dfca8",
            "85bd9d1f44c54a97803d69e88d87bad7",
            "ae0380223c294744977e1f6946c04dda",
            "dea789c5fa3548839384b26bc2d5a8a7"
          ]
        },
        "id": "askqlJwBM6DY",
        "outputId": "283cd491-5b48-48df-b98f-3303df4b70c5"
      },
      "source": [
        "%%time\n",
        "glove_emb_matrix = load_emb_matrix(glove)"
      ],
      "execution_count": 115,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "844c4f88cb8b4103bcce60e1a47fc85f",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=345785.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "CPU times: user 4min 3s, sys: 6.7 s, total: 4min 10s\n",
            "Wall time: 4min 9s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104,
          "referenced_widgets": [
            "e92864da1bff40dfa49182e6abbe3997",
            "562ae141f82540aeaa11daf1c32fe347",
            "dd69cc7940ca4c4c8a6b5340d1f82083",
            "fb73ab7a2a09443f9e02a8639439c6c5",
            "c06f8a1a124243eca4eefd29549e3959",
            "38bcbf9bed274a1c80ae081059d36cba",
            "b7fb8c65e1d4494d99eb54883c6a16bb",
            "4818ae0098634bf592463b1e12918178"
          ]
        },
        "id": "yx7a7vz_M6A0",
        "outputId": "9299796c-0789-4931-c90f-e641c6131054"
      },
      "source": [
        "%%time\n",
        "para_emb_matrix = load_emb_matrix(para)"
      ],
      "execution_count": 116,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e92864da1bff40dfa49182e6abbe3997",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=345785.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "CPU times: user 3min 16s, sys: 4.28 s, total: 3min 20s\n",
            "Wall time: 3min 19s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fQk2qcLAM5-V"
      },
      "source": [
        "emb_matrix = np.mean((0.7 * glove_emb_matrix, 0.3 * para_emb_matrix), axis=0)"
      ],
      "execution_count": 117,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YZQjJW4q5822"
      },
      "source": [
        "Training\n",
        "\n",
        "https://www.kaggle.com/dohyun141/bilstm-pytorch-and-keras/edit"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QjpF54NDM55V"
      },
      "source": [
        "def train_model(model, train_X=train_X, train_y=train_y, n_splits=n_splits):\n",
        "    splits = list(StratifiedKFold(n_splits=n_splits, shuffle=True).split(train_X, train_y))\n",
        "    train_y = np.array(train_y)\n",
        "\n",
        "    train_oof_preds = np.zeros((train_X.shape[0]))\n",
        "    for i, (train_idx, val_idx) in enumerate(splits):\n",
        "        print(f'Fold {i + 1}')\n",
        "\n",
        "        train_X_fold = train_X[train_idx.astype(int)]\n",
        "        train_y_fold = train_y[train_idx.astype(int)]\n",
        "        val_X_fold = train_X[val_idx.astype(int)]\n",
        "        val_y_fold = train_y[val_idx.astype(int)]\n",
        "\n",
        "        clf = copy.deepcopy(model)\n",
        "        clf.fit(train_X_fold, train_y_fold, batch_size=batch_size, epochs=max_epoch, validation_data=(val_X_fold, val_y_fold))\n",
        "        \n",
        "        valid_preds_fold = clf.predict(val_X_fold)[:,0]\n",
        "\n",
        "        train_oof_preds[valid_idx] = valid_preds_fold\n",
        "  \n",
        "    return train_oof_preds"
      ],
      "execution_count": 126,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8vhAcU6uELbE"
      },
      "source": [
        "def make_model(embedding_matrix):\n",
        "    inp = Input(shape=(maxlen,))\n",
        "    x = Embedding(max_features, embed_size, weights=[embedding_matrix],trainable=False)(inp)\n",
        "\n",
        "    x = Bidirectional(CuDNNLSTM(64, return_sequences=True))(x)\n",
        "    avg_pool = GlobalAveragePooling1D()(x)\n",
        "    max_pool = GlobalMaxPooling1D()(x)\n",
        "    conc = concatenate([avg_pool, max_pool])\n",
        "    conc = Dense(64, activation=\"relu\")(conc)\n",
        "    conc = Dropout(0.1)(conc)\n",
        "    outp = Dense(1, activation=\"sigmoid\")(conc)\n",
        "    model = Model(inputs=inp, outputs=outp)\n",
        "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "    return model"
      ],
      "execution_count": 132,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ezUkIiLhHfQz",
        "outputId": "07452729-b7a2-4ab2-e119-d8b3c09207d2"
      },
      "source": [
        "train_X[100]"
      ],
      "execution_count": 153,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([     0,      0,      0,      0,      0,      0,      0,      0,\n",
              "            0,      0,      0,      0,      0,      0,      0,      0,\n",
              "            0,      0,      0,      0,      0,      0,      0,      0,\n",
              "            0,      0,      0,      0,      0,      0,      0,      0,\n",
              "            0,      0,      0,      0,      0,      0,      0,      0,\n",
              "            0,      0,      0,      0,      0,      0,      0,      0,\n",
              "            0,      0,      0,      3,     14,   7363,     12,   7208,\n",
              "           12,    283,   1938,     11,   7261,     78,      8,   2492,\n",
              "        40111,     29, 149435,   5458,    146,      1], dtype=int32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 153
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AYgqQUxBHquk",
        "outputId": "d794d700-fa84-4e83-8d12-9aca1fa46ed1"
      },
      "source": [
        "len(train_y)"
      ],
      "execution_count": 139,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1306122"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 139
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rRo7llPQISZs",
        "outputId": "fe227418-e335-4c44-ced8-cddfd1113e2e"
      },
      "source": [
        "emb_matrix.shape"
      ],
      "execution_count": 142,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(120000, 300)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 142
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WyoOpq4vELfX"
      },
      "source": [
        "model = make_model(emb_matrix)"
      ],
      "execution_count": 144,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UE7FebO8KJFI"
      },
      "source": [
        "SEED=1"
      ],
      "execution_count": 154,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bA3N7EikIh8v"
      },
      "source": [
        "def model_train_cv(x_train,y_train,nfold,model_obj):\n",
        "    splits = list(StratifiedKFold(n_splits=nfold, shuffle=True, random_state=SEED).split(x_train, y_train))\n",
        "    x_train = x_train\n",
        "    y_train = np.array(y_train)\n",
        "    # matrix for the out-of-fold predictions\n",
        "    train_oof_preds = np.zeros((x_train.shape[0]))\n",
        "    for i, (train_idx, valid_idx) in enumerate(splits):\n",
        "        print(f'Fold {i + 1}')\n",
        "        x_train_fold = x_train[train_idx.astype(int)]\n",
        "        y_train_fold = y_train[train_idx.astype(int)]\n",
        "        x_val_fold = x_train[valid_idx.astype(int)]\n",
        "        y_val_fold = y_train[valid_idx.astype(int)]\n",
        "\n",
        "        clf = copy.deepcopy(model_obj)\n",
        "        clf.fit(x_train_fold, y_train_fold, batch_size=512, epochs=5, validation_data=(x_val_fold, y_val_fold))\n",
        "        \n",
        "        valid_preds_fold = clf.predict(x_val_fold)[:,0]\n",
        "\n",
        "        # storing OOF predictions\n",
        "        train_oof_preds[valid_idx] = valid_preds_fold\n",
        "    return train_oof_preds\n"
      ],
      "execution_count": 158,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 633
        },
        "id": "eS10acQvIi2R",
        "outputId": "b8e3f6a8-0dcb-4ede-90d1-384187a2b202"
      },
      "source": [
        "train_oof_preds = model_train_cv(train_X[:8000], train_y[:8000], 5, model)"
      ],
      "execution_count": 159,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fold 1\n",
            "Epoch 1/5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "AssertionError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-159-ca82ff50f95c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_oof_preds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_train_cv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_X\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m8000\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_y\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m8000\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-158-a7195d8595de>\u001b[0m in \u001b[0;36mmodel_train_cv\u001b[0;34m(x_train, y_train, nfold, model_obj)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mclf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_obj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m         \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train_fold\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train_fold\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m512\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_val_fold\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val_fold\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0mvalid_preds_fold\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_val_fold\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1156\u001b[0m                 _r=1):\n\u001b[1;32m   1157\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1158\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1159\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1160\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    887\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m   \u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m   \u001b[0;34m@\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_signature\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensorSpec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mreturn\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1.\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m   \u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    931\u001b[0m   \u001b[0;32mis\u001b[0m \u001b[0minvoked\u001b[0m \u001b[0mto\u001b[0m \u001b[0mtrace\u001b[0m \u001b[0ma\u001b[0m \u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    932\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 933\u001b[0;31m   \u001b[0mThe\u001b[0m \u001b[0msame\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mtrue\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mcode\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mPython\u001b[0m \u001b[0mside\u001b[0m \u001b[0meffects\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mused\u001b[0m \u001b[0minside\u001b[0m \u001b[0mcontrol\u001b[0m \u001b[0mflow\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    934\u001b[0m   \u001b[0msuch\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0ma\u001b[0m \u001b[0mloop\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mIf\u001b[0m \u001b[0myour\u001b[0m \u001b[0mcode\u001b[0m \u001b[0muses\u001b[0m \u001b[0mside\u001b[0m \u001b[0meffects\u001b[0m \u001b[0mthat\u001b[0m \u001b[0mare\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mintended\u001b[0m \u001b[0mto\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    935\u001b[0m   \u001b[0mcontrol\u001b[0m \u001b[0mgraph\u001b[0m \u001b[0mconstruction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwrap\u001b[0m \u001b[0mthem\u001b[0m \u001b[0minside\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpy_func\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_initialize\u001b[0;34m(self, args, kwds, add_initializers_to)\u001b[0m\n\u001b[1;32m    762\u001b[0m   \u001b[0;31m# control flow statements include `if`, `for`, `while`, `break`, `continue`,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    763\u001b[0m   \u001b[0;31m# `return`.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 764\u001b[0;31m   \u001b[0;34m@\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    765\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    766\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduce_sum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_get_concrete_function_internal_garbage_collected\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[0;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    670\u001b[0m       \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0minputs\u001b[0m \u001b[0mto\u001b[0m \u001b[0mspecialize\u001b[0m \u001b[0mon\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    671\u001b[0m       \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0minputs\u001b[0m \u001b[0mto\u001b[0m \u001b[0mspecialize\u001b[0m \u001b[0mon\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 672\u001b[0;31m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    673\u001b[0m     \u001b[0mReturns\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    674\u001b[0m       \u001b[0mA\u001b[0m \u001b[0mTensorFlow\u001b[0m \u001b[0mfunction\u001b[0m \u001b[0mwhich\u001b[0m \u001b[0mtakes\u001b[0m \u001b[0mexactly\u001b[0m \u001b[0mone\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0mper\u001b[0m \u001b[0margument\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    984\u001b[0m   \"\"\"\n\u001b[1;32m    985\u001b[0m   \u001b[0;31m# TODO(b/115366440): Delete this method when a custom OrderedDict is added.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 986\u001b[0;31m   \u001b[0;31m# Clearing captures using clear() leaves some cycles around.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    987\u001b[0m   \u001b[0;32mwhile\u001b[0m \u001b[0mfunc_graph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptures\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    988\u001b[0m     \u001b[0mfunc_graph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptures\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpopitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAssertionError\u001b[0m: in user code:\n\n    /usr/local/lib/python3.7/dist-packages/keras/engine/training.py:830 train_function  *\n        return step_function(self, iterator)\n    /usr/local/lib/python3.7/dist-packages/keras/engine/training.py:813 run_step  *\n        outputs = model.train_step(data)\n    /usr/local/lib/python3.7/dist-packages/keras/engine/training.py:770 train_step  *\n        y_pred = self(x, training=True)\n    /usr/local/lib/python3.7/dist-packages/keras/engine/base_layer.py:1006 __call__  *\n        outputs = call_fn(inputs, *args, **kwargs)\n    /usr/local/lib/python3.7/dist-packages/keras/engine/functional.py:416 call  *\n        inputs, training=training, mask=mask)\n    /usr/local/lib/python3.7/dist-packages/keras/engine/functional.py:560 _run_internal_graph  *\n        assert x_id in tensor_dict, 'Could not compute output ' + str(x)\n\n    AssertionError: Could not compute output KerasTensor(type_spec=TensorSpec(shape=(None, 1), dtype=tf.float32, name=None), name='dense_7/Sigmoid:0', description=\"created by layer 'dense_7'\")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 633
        },
        "id": "Se_KkeT-Cx-u",
        "outputId": "644d4367-70be-4667-e889-e5baf8bead4e"
      },
      "source": [
        "train_oof_preds = train_model(model)"
      ],
      "execution_count": 134,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fold 1\n",
            "Epoch 1/5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "AssertionError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-134-bde55e44e8fa>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_oof_preds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-126-267bbed82910>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(model, train_X, train_y, n_splits)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mclf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m         \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_X_fold\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_y_fold\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_epoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_X_fold\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_y_fold\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0mvalid_preds_fold\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_X_fold\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1156\u001b[0m                 _r=1):\n\u001b[1;32m   1157\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1158\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1159\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1160\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    887\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    931\u001b[0m       \u001b[0;31m# This is the first call of __call__, so we have to initialize.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    932\u001b[0m       \u001b[0minitializers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 933\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madd_initializers_to\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitializers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    934\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    935\u001b[0m       \u001b[0;31m# At this point we know that the initialization is complete (or less\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_initialize\u001b[0;34m(self, args, kwds, add_initializers_to)\u001b[0m\n\u001b[1;32m    762\u001b[0m     self._concrete_stateful_fn = (\n\u001b[1;32m    763\u001b[0m         self._stateful_fn._get_concrete_function_internal_garbage_collected(  # pylint: disable=protected-access\n\u001b[0;32m--> 764\u001b[0;31m             *args, **kwds))\n\u001b[0m\u001b[1;32m    765\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    766\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0minvalid_creator_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0munused_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0munused_kwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_get_concrete_function_internal_garbage_collected\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3048\u001b[0m       \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3049\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3050\u001b[0;31m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3051\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3052\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   3442\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3443\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3444\u001b[0;31m           \u001b[0mgraph_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3445\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3446\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[0;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m   3287\u001b[0m             \u001b[0marg_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0marg_names\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3288\u001b[0m             \u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3289\u001b[0;31m             capture_by_value=self._capture_by_value),\n\u001b[0m\u001b[1;32m   3290\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_attributes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3291\u001b[0m         \u001b[0mfunction_spec\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_spec\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m    997\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    998\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 999\u001b[0;31m       \u001b[0mfunc_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1000\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1001\u001b[0m       \u001b[0;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    670\u001b[0m         \u001b[0;31m# the function a weak reference to itself to avoid a reference cycle.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    671\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcompile_with_xla\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 672\u001b[0;31m           \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    673\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    674\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    984\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    985\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ag_error_metadata\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 986\u001b[0;31m               \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    987\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    988\u001b[0m               \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAssertionError\u001b[0m: in user code:\n\n    /usr/local/lib/python3.7/dist-packages/keras/engine/training.py:830 train_function  *\n        return step_function(self, iterator)\n    /usr/local/lib/python3.7/dist-packages/keras/engine/training.py:813 run_step  *\n        outputs = model.train_step(data)\n    /usr/local/lib/python3.7/dist-packages/keras/engine/training.py:770 train_step  *\n        y_pred = self(x, training=True)\n    /usr/local/lib/python3.7/dist-packages/keras/engine/base_layer.py:1006 __call__  *\n        outputs = call_fn(inputs, *args, **kwargs)\n    /usr/local/lib/python3.7/dist-packages/keras/engine/functional.py:416 call  *\n        inputs, training=training, mask=mask)\n    /usr/local/lib/python3.7/dist-packages/keras/engine/functional.py:560 _run_internal_graph  *\n        assert x_id in tensor_dict, 'Could not compute output ' + str(x)\n\n    AssertionError: Could not compute output KerasTensor(type_spec=TensorSpec(shape=(None, 1), dtype=tf.float32, name=None), name='dense_5/Sigmoid:0', description=\"created by layer 'dense_5'\")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 819
        },
        "id": "ebog3sxKCYep",
        "outputId": "6f6c2324-da6d-46ad-d4fd-836041e87db5"
      },
      "source": [
        "!pip install tensorflow==2.0.0b1"
      ],
      "execution_count": 157,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tensorflow==2.0.0b1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7b/43/dcf19f30fb1da9e971e591d95e56c7b9d4e417f4a203ad272eb746742f42/tensorflow-2.0.0b1-cp37-cp37m-manylinux1_x86_64.whl (88.7MB)\n",
            "\u001b[K     |████████████████████████████████| 88.7MB 59kB/s \n",
            "\u001b[?25hRequirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.0.0b1) (0.12.0)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.0.0b1) (1.34.1)\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.0.0b1) (0.2.0)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.0.0b1) (0.36.2)\n",
            "Collecting tf-estimator-nightly<1.14.0.dev2019060502,>=1.14.0.dev2019060501\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/32/dd/99c47dd007dcf10d63fd895611b063732646f23059c618a373e85019eb0e/tf_estimator_nightly-1.14.0.dev2019060501-py2.py3-none-any.whl (496kB)\n",
            "\u001b[K     |████████████████████████████████| 501kB 45.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.0.0b1) (1.12.1)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.0.0b1) (1.15.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.0.0b1) (1.1.0)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.0.0b1) (3.12.4)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.0.0b1) (0.8.1)\n",
            "Collecting tb-nightly<1.14.0a20190604,>=1.14.0a20190603\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a4/96/571b875cd81dda9d5dfa1422a4f9d749e67c0a8d4f4f0b33a4e5f5f35e27/tb_nightly-1.14.0a20190603-py3-none-any.whl (3.1MB)\n",
            "\u001b[K     |████████████████████████████████| 3.1MB 41.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy<2.0,>=1.14.5 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.0.0b1) (1.19.5)\n",
            "Collecting keras-applications>=1.0.6\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/71/e3/19762fdfc62877ae9102edf6342d71b28fbfd9dea3d2f96a882ce099b03f/Keras_Applications-1.0.8-py3-none-any.whl (50kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 6.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.0.0b1) (1.1.2)\n",
            "Requirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.0.0b1) (0.4.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from protobuf>=3.6.1->tensorflow==2.0.0b1) (57.0.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tb-nightly<1.14.0a20190604,>=1.14.0a20190603->tensorflow==2.0.0b1) (3.3.4)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tb-nightly<1.14.0a20190604,>=1.14.0a20190603->tensorflow==2.0.0b1) (1.0.1)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from keras-applications>=1.0.6->tensorflow==2.0.0b1) (3.1.0)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tb-nightly<1.14.0a20190604,>=1.14.0a20190603->tensorflow==2.0.0b1) (4.5.0)\n",
            "Requirement already satisfied: cached-property; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from h5py->keras-applications>=1.0.6->tensorflow==2.0.0b1) (1.5.2)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tb-nightly<1.14.0a20190604,>=1.14.0a20190603->tensorflow==2.0.0b1) (3.7.4.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tb-nightly<1.14.0a20190604,>=1.14.0a20190603->tensorflow==2.0.0b1) (3.4.1)\n",
            "\u001b[31mERROR: kapre 0.3.5 has requirement tensorflow>=2.0.0, but you'll have tensorflow 2.0.0b1 which is incompatible.\u001b[0m\n",
            "Installing collected packages: tf-estimator-nightly, tb-nightly, keras-applications, tensorflow\n",
            "  Found existing installation: tensorflow 2.5.0\n",
            "    Uninstalling tensorflow-2.5.0:\n",
            "      Successfully uninstalled tensorflow-2.5.0\n",
            "Successfully installed keras-applications-1.0.8 tb-nightly-1.14.0a20190603 tensorflow-2.0.0b1 tf-estimator-nightly-1.14.0.dev2019060501\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "tensorboard",
                  "tensorflow"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5ejXdTQCCYhh"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7XcRVoS-CYnz"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NrVaEnzcAGlw",
        "outputId": "c6b3f151-35ea-4ff6-ba86-509eaa1bf215"
      },
      "source": [
        "pad_sequences(train_X).shape[0]"
      ],
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1306122"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 94
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6zrPkG8i5GsL",
        "outputId": "a0787d4a-f91a-4b23-bba6-ea7c06bfeefc"
      },
      "source": [
        "train_y"
      ],
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 0, 0, ..., 0, 0, 0])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 96
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3d17IG6t-n1k",
        "outputId": "b9c5cc46-2dc1-49d5-8925-e7728b2641ad"
      },
      "source": [
        "np.zeros(100)"
      ],
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 97
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J-M9j3I1_O5l",
        "outputId": "7e650c7d-d070-461b-e1da-19cd04bf7fde"
      },
      "source": [
        "np.zeros((100))"
      ],
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 98
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6PT1loiB_O89"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FjapbHOs_O_-"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qJMfFeyM_PC6"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3MPRbQHK-n4n",
        "outputId": "e392f9a8-34ab-4d22-8a75-405329c28f72"
      },
      "source": [
        "len(a)"
      ],
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1044897"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 79
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xKFtSxXJ-n7L",
        "outputId": "368aac91-3ae2-4049-b5c7-f91b77dd0640"
      },
      "source": [
        "b"
      ],
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['Is it just me or have you ever been in this phase wherein you became ignorant to the people you once loved , completely disregarding their feelings /lives so you get to have something go your way and feel temporarily at ease . How did things change ?',\n",
              "       'How were the Calgary Flames founded ?',\n",
              "       'I am 30 , living at home and have no boyfriend . I would love a boyfriend and my own home . How can I progress my situation ?',\n",
              "       ..., 'How is DSATM civil engineering ?',\n",
              "       'What is your story today ?',\n",
              "       'What other technical skills do you need as a computer science undergrad other than c and c + + ?'],\n",
              "      dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 80
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UQFjs0zw-n9s",
        "outputId": "5e1e3788-476e-46a0-aa61-87971bfa679c"
      },
      "source": [
        "len(b)"
      ],
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "261225"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 81
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-4PjsJEI-_pq"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0B1v-LbS-_uL"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mlZlBXiJ-_xI"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jaT4f1j15Gup"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kIpQB79S5GxC"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uW72bERSM5nq"
      },
      "source": [
        ""
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o_dxcjft2N-X"
      },
      "source": [
        "references:\n",
        "\n",
        "https://www.kaggle.com/strideradu/word2vec-and-gensim-go-go-go\n",
        "\n",
        "https://www.kaggle.com/alhalimi/tokenization-and-word-embedding-compatibility\n",
        "\n",
        "https://www.kaggle.com/canming/ensemble-mean-iii-64-36\n",
        "\n",
        "https://www.kaggle.com/tks0123456789/pme-ema-6-x-8-epochs\n",
        "\n",
        "https://www.kaggle.com/bkkaggle/pytorch-determinism-test\n",
        "\n",
        "https://www.kaggle.com/hsinwenchang/more-bidirectional-cudnnlstm-layer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xE-qeWSb90RE"
      },
      "source": [
        "Please verify your config values."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yikpuyek9zUt"
      },
      "source": [
        "seed = 31\n",
        "n_splits = 5\n",
        "input_path = '/content/drive/MyDrive/ColabNotebooks/QIQC/data'"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fkey34_e-Ol7"
      },
      "source": [
        "def seed_torch(seed=seed):\n",
        "    random.seed(seed)\n",
        "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    torch.backends.cudnn.deterministic = True"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "puVJ-UQT19m6",
        "outputId": "1d6c7571-1754-4d5f-a91d-3e99b1e414f2"
      },
      "source": [
        "import gc\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tqdm.auto import tqdm\n",
        "tqdm.pandas()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tqdm/std.py:658: FutureWarning: The Panel class is removed from pandas. Accessing it from the top-level namespace will also be removed in the next version\n",
            "  from pandas import Panel\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qevZ5b952EY1"
      },
      "source": [
        "import os\n",
        "\n",
        "train_path = os.path.join(input_path, 'train.csv')\n",
        "test_path = os.path.join(input_path, 'test.csv')\n",
        "embeddings_path = os.path.join(input_path, 'embeddings.zip')"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 615
        },
        "id": "kJAquR832FUV",
        "outputId": "3709fc4a-31e9-47d5-87f2-5ddf48cb874a"
      },
      "source": [
        "if os.path.exists(train_path): train_df = pd.read_csv(train_path)\n",
        "else: train_df = pd.read_csv(train_path + '.zip')\n",
        "\n",
        "if os.path.exists(test_path): test_df = pd.read_csv(train_path)\n",
        "else: test_df = pd.read_csv(test_path + '.zip')\n",
        "\n",
        "print('train shape:', train_df.shape)\n",
        "print('test shape:', test_df.shape)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-14-4c97a98a02d7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtrain_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_path\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'.zip'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mif\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtest_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtest_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_path\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'.zip'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    686\u001b[0m     )\n\u001b[1;32m    687\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 688\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    689\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    690\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    458\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 460\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    461\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    462\u001b[0m         \u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m   1196\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1197\u001b[0m         \u001b[0mnrows\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_validate_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"nrows\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1198\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1199\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1200\u001b[0m         \u001b[0;31m# May alter columns / col_dict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m   2155\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2156\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2157\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2158\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2159\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_first_chunk\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.read\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._read_low_memory\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._read_rows\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._convert_column_data\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._convert_tokens\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._convert_with_dtype\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/dtypes/common.py\u001b[0m in \u001b[0;36mis_categorical_dtype\u001b[0;34m(arr_or_dtype)\u001b[0m\n\u001b[1;32m    528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    529\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 530\u001b[0;31m \u001b[0;32mdef\u001b[0m \u001b[0mis_categorical_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr_or_dtype\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    531\u001b[0m     \"\"\"\n\u001b[1;32m    532\u001b[0m     \u001b[0mCheck\u001b[0m \u001b[0mwhether\u001b[0m \u001b[0man\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mlike\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mCategorical\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kwnVZber2GKI"
      },
      "source": [
        "import zipfile\n",
        "from gensim.models import KeyedVectors\n",
        "\n",
        "glove = 'glove.840B.300d/glove.840B.300d.txt'\n",
        "wiki = 'wiki-news-300d-1M/wiki-news-300d-1M.vec'\n",
        "google = 'GoogleNews-vectors-negative300/GoogleNews-vectors-negative300.bin'\n",
        "para = 'paragram_300_sl999/paragram_300_sl999.txt'\n",
        "\n",
        "\n",
        "def load_embedding(embedding_name):\n",
        "\n",
        "    def get_coefs(word, *arr): return word, np.asarray(arr, dtype='float32')\n",
        "\n",
        "    with zipfile.ZipFile(embeddings_path) as embeddings_zip:\n",
        "        print(\"Found embeddings as a zip file\")\n",
        "\n",
        "        if embedding_name == google:\n",
        "            return KeyedVectors.load_word2vec_format(embeddings_zip.open(google), binary=True)\n",
        "\n",
        "        else:\n",
        "            embedding = []\n",
        "            for o in embeddings_zip.open(embedding_name):\n",
        "                try:\n",
        "                    if len(o.decode('utf-8')) > 100:\n",
        "                        embedding.append(get_coefs(*o.decode('utf-8').split(\" \")))\n",
        "                except:\n",
        "                    pass\n",
        "        \n",
        "        return dict(embedding)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kw5nfIQg28be"
      },
      "source": [
        "%%time\n",
        "glove_embedding = load_embedding(glove)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vfqRFZyl4hfH"
      },
      "source": [
        "Some features about glove_embedding"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UxyZ8KkX3APZ"
      },
      "source": [
        "\"'re\" in glove_embedding"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EjW67U0y37X6"
      },
      "source": [
        "\"you're\" in glove_embedding"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8RmhpLd84Bo4"
      },
      "source": [
        "\"12345\" in glove_embedding"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z7IeyeiN4XMq"
      },
      "source": [
        "\"'m\" in glove_embedding"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7sHczpxEG-yB"
      },
      "source": [
        "for punct in '!\"#$%&()*+,-./:;<=>?@[\\]^_`{|}~‘’“”…' + \"'\":\n",
        "    if punct not in glove_embedding: print(punct)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "okUrz7WW4x8b"
      },
      "source": [
        "We use all tokens from both train and test data for our vocabulary.\n",
        "\n",
        "Tokenizer : keras"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7z7m8gIzT4uG"
      },
      "source": [
        "puncts = '´‘’“”…!#$%&()*+,-./:;<=>?@[\\]^_`{|}~\"' + \"'\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G63jvrCA4wpl"
      },
      "source": [
        "from keras.preprocessing.text import Tokenizer\n",
        "\n",
        "to_exclude = ''\n",
        "to_tokenize = puncts\n",
        "\n",
        "tokenizer = Tokenizer(filters=to_exclude, lower=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1FFLTyLm5PGV"
      },
      "source": [
        "from sklearn.model_selection import train_test_split, KFold\n",
        "\n",
        "kfold = KFold(n_splits=n_splits, shuffle=True, random_state=seed)\n",
        "\n",
        "train_df, val_df = train_test_split(train_df, test_size=0.1)\n",
        "\n",
        "train_idx, val_idx = list(kfold.split(train_df))[0]\n",
        "train_df, val_df = train_df.iloc[train_idx], train_df.iloc[val_idx]\n",
        "\n",
        "train_text = train_df[\"question_text\"].fillna(\"_na_\")\n",
        "val_text = val_df[\"question_text\"].fillna(\"_na_\")\n",
        "test_text = test_df[\"question_text\"].fillna(\"_na_\")\n",
        "\n",
        "train_y = train_df['target'].values\n",
        "val_y = val_df['target'].values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-LNA5SZaJPPw"
      },
      "source": [
        "import re\n",
        "\n",
        "train_text = train_text.progress_apply(lambda x: re.sub(r'(['+to_tokenize+'])', r' \\1', x)).values\n",
        "val_text = val_text.progress_apply(lambda x: re.sub(r'(['+to_tokenize+'])', r' \\1', x)).values\n",
        "test_text = test_text.progress_apply(lambda x: re.sub(r'(['+to_tokenize+'])', r' \\1', x)).values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KBD2uVNw5hGj"
      },
      "source": [
        "text = list(train_text) + list(val_text) + list(test_text)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sI7SY5-75sxJ"
      },
      "source": [
        "%%time\n",
        "tokenizer.fit_on_texts(text)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "waTUAXSk63mu"
      },
      "source": [
        "word_index = tokenizer.word_index"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8WyhLLNX6L_J"
      },
      "source": [
        "%%time\n",
        "train_X = tokenizer.texts_to_sequences(train_text)\n",
        "val_X = tokenizer.texts_to_sequences(val_text)\n",
        "test_X = tokenizer.texts_to_sequences(test_text)\n",
        "\n",
        "maxlen = max({len(seq) for seq in train_X} | {len(seq) for seq in val_X} | {len(seq) for seq in test_X})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k5hCr1Hx7uMx"
      },
      "source": [
        "from keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "train_X = pad_sequences(train_X, maxlen=maxlen)\n",
        "val_X = pad_sequences(val_X, maxlen=maxlen)\n",
        "test_X = pad_sequences(test_X, maxlen=maxlen)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F6n-TdpmAcov"
      },
      "source": [
        "glove_emb_mean, glove_emb_std = -0.005838499, 0.48782197"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bqkoa-rxAczd"
      },
      "source": [
        "embed_size = 300 # how big is each word vector\n",
        "max_features = len(word_index) # how many unique words to use (i.e num rows in embedding vector)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RTzgD16HEF2a"
      },
      "source": [
        "Without any effort"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a_1eZGfVNgYG"
      },
      "source": [
        "show_inital_emb_matrix = True # set False if you do not want to see the intial embedding matrix"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Tgc4vYNEEbf"
      },
      "source": [
        "if show_inital_emb_matrix:\n",
        "    glove_emb_matrix = np.random.normal(glove_emb_mean, glove_emb_std, (max_features, embed_size))\n",
        "    glove_oov = {}\n",
        "    for word, i in tqdm(word_index.items()):\n",
        "        if word in glove_embedding:\n",
        "            glove_emb_matrix[i] = glove_embedding[word]\n",
        "        \n",
        "        else:\n",
        "            glove_oov[word] = id\n",
        "\n",
        "    print('percentage of oov of glove: {:.2f}%'.format(len(glove_oov) / max_features * 100))\n",
        "\n",
        "else:\n",
        "    print('percentage of oov of glove: 41.39%')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pxbIBq26EoQ_"
      },
      "source": [
        "Let's make an improved embedding matrix."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jn_PWdXy9SSG"
      },
      "source": [
        "import nltk\n",
        "# nltk.download('wordnet')\n",
        "\n",
        "from nltk.stem import PorterStemmer\n",
        "from nltk.stem import LancasterStemmer\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "s = PorterStemmer()\n",
        "l = LancasterStemmer()\n",
        "n = WordNetLemmatizer()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TYybM4HKPa-Q"
      },
      "source": [
        "def is_in_emb(word, i, embedding, emb_matrix):\n",
        "\n",
        "    if word in embedding:\n",
        "        emb_matrix[i] = embedding[word]\n",
        "        return True\n",
        "    \n",
        "    tmp = word.lower()\n",
        "    if tmp in embedding:\n",
        "        emb_matrix[i] = embedding[tmp]\n",
        "        return True\n",
        "    \n",
        "    tmp = word.upper()\n",
        "    if tmp in embedding:\n",
        "        emb_matrix[i] = embedding[tmp]\n",
        "        return True\n",
        "\n",
        "    tmp = word.capitalize()\n",
        "    if tmp in embedding:\n",
        "        emb_matrix[i] = embedding[tmp]\n",
        "        return True\n",
        "\n",
        "    tmp = s.stem(word)\n",
        "    if tmp in embedding:\n",
        "        emb_matrix[i] = embedding[tmp]\n",
        "        return True\n",
        "    \n",
        "    tmp = l.stem(word)\n",
        "    if tmp in embedding:\n",
        "        emb_matrix[i] = embedding[tmp]\n",
        "        return True\n",
        "    \n",
        "    tmp = n.lemmatize(word)\n",
        "    if tmp in embedding:\n",
        "        emb_matrix[i] = embedding[tmp]\n",
        "        return True\n",
        "    \n",
        "    return False"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "awWKH0x5AAWg"
      },
      "source": [
        "glove_emb_matrix = np.random.normal(glove_emb_mean, glove_emb_std, (max_features, embed_size))\n",
        "glove_oov = {}\n",
        "# double_continue = False\n",
        "for word, i in tqdm(word_index.items()):\n",
        "    i -= 1\n",
        "    assert i >= 0\n",
        "\n",
        "    if is_in_emb(word, i, glove_embedding, glove_emb_matrix): continue\n",
        "\n",
        "    tmp = word\n",
        "    for punct in puncts:\n",
        "        tmp = tmp.replace(punct, '')\n",
        "    if is_in_emb(tmp, i, glove_embedding, glove_emb_matrix): continue\n",
        "\n",
        "    for num in '0123456789':\n",
        "        tmp = tmp.replace(num, '')\n",
        "    if is_in_emb(tmp, i, glove_embedding, glove_emb_matrix): continue\n",
        "\n",
        "    else:\n",
        "        glove_oov[word] = i\n",
        "\n",
        "print('percentage of oov of glove: {:.2f}%'.format(len(glove_oov) / max_features * 100))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GGGXlLi0E5Rq"
      },
      "source": [
        "del glove_embedding\n",
        "gc.collect()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bzn3xBCeUbZl"
      },
      "source": [
        "41.39% -> 14.11%"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ji5b5Nx8VAa0"
      },
      "source": [
        "Wiki"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pt4c9s0fD5vS"
      },
      "source": [
        "%%time\n",
        "wiki_embedding = load_embedding(wiki)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "48TQgADWV7t6"
      },
      "source": [
        "for punct in '!\"#$%&()*+,-./:;<=>?@[\\]^_`{|}~‘’“”…' + \"'\":\n",
        "    if punct not in wiki_embedding: print(punct)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5XPEz6NbV7wT"
      },
      "source": [
        "\"3123\" in wiki_embedding"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nryA7GUeV7yo"
      },
      "source": [
        "\"I'm\" in wiki_embedding"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ovDGEsXIWeFI"
      },
      "source": [
        "\"'m\" in wiki_embedding"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3dWk3jHMD5xl"
      },
      "source": [
        "wiki_emb_mean, wiki_emb_std = -0.0033469985, 0.109855495"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gl6oSVYkD5zt"
      },
      "source": [
        "if show_inital_emb_matrix:\n",
        "    wiki_emb_matrix = np.random.normal(wiki_emb_mean, wiki_emb_std, (max_features, embed_size))\n",
        "    wiki_oov = {}\n",
        "    for word, i in tqdm(word_index.items()):\n",
        "        if word in wiki_embedding:\n",
        "            wiki_emb_matrix[i] = wiki_embedding[word]\n",
        "        \n",
        "        else:\n",
        "            wiki_oov[word] = id\n",
        "\n",
        "    print('percentage of oov of wiki: {:.2f}%'.format(len(wiki_oov) / max_features * 100))\n",
        "\n",
        "else:\n",
        "    print('percentage of oov of wiki: 46.91%')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VON5XZBOD519"
      },
      "source": [
        "wiki_emb_matrix = np.random.normal(wiki_emb_mean, wiki_emb_std, (max_features, embed_size))\n",
        "wiki_oov = {}\n",
        "# double_continue = False\n",
        "for word, i in tqdm(word_index.items()):\n",
        "    i -= 1\n",
        "    assert i >= 0\n",
        "\n",
        "    if is_in_emb(word, i, wiki_embedding, wiki_emb_matrix): continue\n",
        "\n",
        "    tmp = word\n",
        "    for punct in puncts:\n",
        "        tmp = tmp.replace(punct, '')\n",
        "    if is_in_emb(tmp, i, wiki_embedding, wiki_emb_matrix): continue\n",
        "\n",
        "    for num in '0123456789':\n",
        "        tmp = tmp.replace(num, '')\n",
        "    if is_in_emb(tmp, i, wiki_embedding, wiki_emb_matrix): continue\n",
        "\n",
        "    else:\n",
        "        wiki_oov[word] = i\n",
        "\n",
        "print('percentage of oov of wiki: {:.2f}%'.format(len(wiki_oov) / max_features * 100))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mrgfNyW1aB32"
      },
      "source": [
        "del wiki_embedding\n",
        "gc.collect()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D4vvM5DrXTVa"
      },
      "source": [
        "google"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4CGuiVAOW_Jj"
      },
      "source": [
        "%%time\n",
        "google_embedding = load_embedding(google)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rkbyDSb5ZMMV"
      },
      "source": [
        "'?' in google_embedding"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cu4MKk7-XW12"
      },
      "source": [
        "google_emb_mean, google_emb_std = -0.003527845, 0.13315111"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BAuwq-gPXZle"
      },
      "source": [
        "google_emb_matrix = np.random.normal(google_emb_mean, google_emb_std, (max_features, embed_size))\n",
        "google_oov = {}\n",
        "# double_continue = False\n",
        "for word, i in tqdm(word_index.items()):\n",
        "    i -= 1\n",
        "    assert i >= 0\n",
        "\n",
        "    if is_in_emb(word, i, google_embedding, google_emb_matrix): continue\n",
        "\n",
        "    tmp = re.sub('[0-9]{5,}', '#####', word)\n",
        "    tmp = re.sub('[0-9]{4}', '####', tmp)\n",
        "    tmp = re.sub('[0-9]{3}', '###', tmp)\n",
        "    tmp = re.sub('[0-9]{2}', '##', tmp)\n",
        "    if is_in_emb(tmp, i, google_embedding, google_emb_matrix): continue\n",
        "\n",
        "    # tmp = word\n",
        "    for punct in puncts:\n",
        "        tmp = tmp.replace(punct, '')\n",
        "    if is_in_emb(tmp, i, google_embedding, google_emb_matrix): continue\n",
        "\n",
        "    else:\n",
        "        google_oov[word] = i\n",
        "\n",
        "print('percentage of oov of google: {:.2f}%'.format(len(google_oov) / max_features * 100))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p-mXb0xeYSI0"
      },
      "source": [
        "google_oov"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "usHQwuvLaGbU"
      },
      "source": [
        "del google_embedding\n",
        "gc.collect()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ES_RGBlNZkd9"
      },
      "source": [
        "para"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IPy8rnZ6ZJ-e"
      },
      "source": [
        "%%time\n",
        "para_embedding = load_embedding(para)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zat7_Y8CZn1C"
      },
      "source": [
        "para_emb_mean, para_emb_std = -0.0053248387, 0.49346521"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HCXnnE2-Zq_W"
      },
      "source": [
        "para_emb_matrix = np.random.normal(para_emb_mean, para_emb_std, (max_features, embed_size))\n",
        "para_oov = {}\n",
        "# double_continue = False\n",
        "for word, i in tqdm(word_index.items()):\n",
        "    i -= 1\n",
        "    assert i >= 0\n",
        "\n",
        "    if is_in_emb(word, i, para_embedding, para_emb_matrix): continue\n",
        "\n",
        "    tmp = word\n",
        "    for punct in puncts:\n",
        "        tmp = tmp.replace(punct, '')\n",
        "    if is_in_emb(tmp, i, para_embedding, para_emb_matrix): continue\n",
        "\n",
        "    for num in '0123456789':\n",
        "        tmp = tmp.replace(num, '')\n",
        "    if is_in_emb(tmp, i, para_embedding, para_emb_matrix): continue\n",
        "\n",
        "    else:\n",
        "        para_oov[word] = i\n",
        "\n",
        "print('percentage of oov of para: {:.2f}%'.format(len(para_oov) / max_features * 100))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tdjc_Q6_ad35"
      },
      "source": [
        "para_oov"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SLXTjJ_AaefG"
      },
      "source": [
        "del para_embedding\n",
        "gc.collect()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}