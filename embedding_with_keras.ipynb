{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "embedding_with_keras.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "mount_file_id": "14imiGNeGGpyUAS_LjCQND9AsaRzv3MYz",
      "authorship_tag": "ABX9TyOt2SL84ONwRTZrURHxf17f",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "0d7c237c9b05433e80cb4cc8f22d05fa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_18fa003b9bc24a749d2e1fff24615904",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_570218a9971347dd94114c076894a2c2",
              "IPY_MODEL_9a8a3c4cf2834f02b5f659760a5f2a15"
            ]
          }
        },
        "18fa003b9bc24a749d2e1fff24615904": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "570218a9971347dd94114c076894a2c2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_d472fe76a37c4048aeb034eb007f2759",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 209286,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 209286,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_139a747ada2e4b4f968bd238dacbd390"
          }
        },
        "9a8a3c4cf2834f02b5f659760a5f2a15": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_64171f7cf99141ceaec9d343f5fad5f6",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 209286/209286 [00:39&lt;00:00, 5333.09it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_f512c346a2ae48dfb22f2c70ab763e70"
          }
        },
        "d472fe76a37c4048aeb034eb007f2759": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "139a747ada2e4b4f968bd238dacbd390": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "64171f7cf99141ceaec9d343f5fad5f6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "f512c346a2ae48dfb22f2c70ab763e70": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dohyun1411/Quora-Insincere-Questions-Classification/blob/preprocessing1/embedding_with_keras.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TRZNHTxB_jbJ"
      },
      "source": [
        "references:\n",
        "\n",
        "https://www.kaggle.com/strideradu/word2vec-and-gensim-go-go-go\n",
        "\n",
        "https://www.kaggle.com/alhalimi/tokenization-and-word-embedding-compatibility\n",
        "\n",
        "https://www.kaggle.com/canming/ensemble-mean-iii-64-36"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wOcuWwrS8nNX",
        "outputId": "af2b1a4b-b7e2-49a6-cd61-a77ce5f99212"
      },
      "source": [
        "import gc\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tqdm.auto import tqdm\n",
        "tqdm.pandas()\n",
        "\n",
        "import tensorflow as tf"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tqdm/std.py:658: FutureWarning: The Panel class is removed from pandas. Accessing it from the top-level namespace will also be removed in the next version\n",
            "  from pandas import Panel\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Th0y_M_R_rer"
      },
      "source": [
        "import time\n",
        "import math\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn import metrics\n",
        "\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.layers import Dense, Input, LSTM, Embedding, Dropout, Activation, CuDNNGRU, Conv1D\n",
        "from keras.layers import Bidirectional, GlobalMaxPooling1D, GlobalAveragePooling1D, concatenate\n",
        "from keras.models import Model\n",
        "from keras import initializers, regularizers, constraints, optimizers, layers"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9W2i5_V98vIt"
      },
      "source": [
        "import os\n",
        "\n",
        "# input_path = '/kaggle/input/quora-insincere-questions-classification'\n",
        "input_path = '/content/drive/MyDrive/ColabNotebooks/QIQC/data'\n",
        "train_path = os.path.join(input_path, 'train.csv')\n",
        "test_path = os.path.join(input_path, 'test.csv')\n",
        "embeddings_path = os.path.join(input_path, 'embeddings.zip')"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dMtlqbXF9DLj",
        "outputId": "60b0ff2a-7dde-450a-8f66-2e1b01c6dc2a"
      },
      "source": [
        "if os.path.exists(train_path): train_df = pd.read_csv(train_path)\n",
        "else: train_df = pd.read_csv(train_path + '.zip')\n",
        "\n",
        "if os.path.exists(test_path): test_df = pd.read_csv(train_path)\n",
        "else: test_df = pd.read_csv(train_path + '.zip')\n",
        "\n",
        "print('train shape:', train_df.shape)\n",
        "print(train_df.head())\n",
        "print()\n",
        "print('test shape:', test_df.shape)\n",
        "print(test_df.head())"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "train shape: (1306122, 3)\n",
            "                    qid  ... target\n",
            "0  00002165364db923c7e6  ...      0\n",
            "1  000032939017120e6e44  ...      0\n",
            "2  0000412ca6e4628ce2cf  ...      0\n",
            "3  000042bf85aa498cd78e  ...      0\n",
            "4  0000455dfa3e01eae3af  ...      0\n",
            "\n",
            "[5 rows x 3 columns]\n",
            "\n",
            "test shape: (1306122, 3)\n",
            "                    qid  ... target\n",
            "0  00002165364db923c7e6  ...      0\n",
            "1  000032939017120e6e44  ...      0\n",
            "2  0000412ca6e4628ce2cf  ...      0\n",
            "3  000042bf85aa498cd78e  ...      0\n",
            "4  0000455dfa3e01eae3af  ...      0\n",
            "\n",
            "[5 rows x 3 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6CwM8vOz_-Cf"
      },
      "source": [
        "# split to train and val\n",
        "train_df, val_df = train_test_split(train_df, test_size=0.1, random_state=2018)\n",
        "\n",
        "# some config values \n",
        "embed_size = 300 # how big is each word vector\n",
        "max_features = 50000 # how many unique words to use (i.e num rows in embedding vector)\n",
        "maxlen = 100 # max number of words in a question to use\n",
        "\n",
        "# fill up the missing values\n",
        "train_X = train_df[\"question_text\"].fillna(\"_na_\").values\n",
        "val_X = val_df[\"question_text\"].fillna(\"_na_\").values\n",
        "test_X = test_df[\"question_text\"].fillna(\"_na_\").values\n",
        "\n",
        "# Get the target values\n",
        "train_y = train_df['target'].values\n",
        "val_y = val_df['target'].values"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rH5Ry0fvArrh",
        "outputId": "1b460875-1d20-463a-c943-809133f251d7"
      },
      "source": [
        "%%time\n",
        "# Tokenize the sentences\n",
        "tokenizer = Tokenizer(num_words=max_features)\n",
        "tokenizer.fit_on_texts(list(train_X))\n",
        "train_X = tokenizer.texts_to_sequences(train_X)\n",
        "val_X = tokenizer.texts_to_sequences(val_X)\n",
        "test_X = tokenizer.texts_to_sequences(test_X)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 51.3 s, sys: 492 ms, total: 51.8 s\n",
            "Wall time: 51.7 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0wzFwXS4A-rM",
        "outputId": "b5f2b921-c821-4305-a185-e9e2a8e21db2"
      },
      "source": [
        "%%time\n",
        "# Pad the sentences \n",
        "train_X = pad_sequences(train_X, maxlen=maxlen)\n",
        "val_X = pad_sequences(val_X, maxlen=maxlen)\n",
        "test_X = pad_sequences(test_X, maxlen=maxlen)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 10.2 s, sys: 297 ms, total: 10.5 s\n",
            "Wall time: 10.4 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t1SZuKNIBeJ-",
        "outputId": "ccb7fcd6-d167-4463-954d-c2f6583eb803"
      },
      "source": [
        "%%time\n",
        "import zipfile\n",
        "from gensim.models import KeyedVectors\n",
        "\n",
        "glove = 'glove.840B.300d/glove.840B.300d.txt'\n",
        "wiki = 'wiki-news-300d-1M/wiki-news-300d-1M.vec'\n",
        "google = 'GoogleNews-vectors-negative300/GoogleNews-vectors-negative300.bin'\n",
        "\n",
        "def get_coefs(word, *arr): return word, np.asarray(arr, dtype='float32')\n",
        "\n",
        "with zipfile.ZipFile(embeddings_path) as embeddings_zip:\n",
        "    print(\"Found embeddings as a zip file\")\n",
        "    glove_embedding = dict(get_coefs(*o.decode('utf-8').split(\" \")) for o in embeddings_zip.open(glove))\n",
        "    wiki_embedding = dict(get_coefs(*o.decode('utf-8').split(\" \")) for o in embeddings_zip.open(wiki))\n",
        "    google_embedding = KeyedVectors.load_word2vec_format(embeddings_zip.open(google), binary=True)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found embeddings as a zip file\n",
            "CPU times: user 6min 13s, sys: 8.22 s, total: 6min 21s\n",
            "Wall time: 6min 22s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n0D2JNPXKgGk"
      },
      "source": [
        "word_index = tokenizer.word_index\n",
        "nb_words = min(max_features, len(word_index))"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D0dvpL-_VnCA"
      },
      "source": [
        "def get_emb_stats(embeddings_index):\n",
        "\n",
        "    # Put all embeddings in a numpy matrix\n",
        "    all_embs= np.stack(embeddings_index.values())\n",
        "\n",
        "    # Get embedding stats\n",
        "    emb_mean = all_embs.mean()\n",
        "    emb_std = all_embs.std()\n",
        "    \n",
        "    num_embs = all_embs.shape[0]\n",
        "    \n",
        "    emb_size = all_embs.shape[1]\n",
        "    \n",
        "    return emb_mean,emb_std, num_embs, emb_size "
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0BmdE-mxWeFK",
        "outputId": "febef1ed-1e5f-43af-a05d-90320f4e5a71"
      },
      "source": [
        "# get_emb_stats(glove_embedding) # The results will be constant so we will not run this function in practice to save time"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py:2882: FutureWarning: arrays to stack must be passed as a \"sequence\" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.\n",
            "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(-0.005838499, 0.48782197, 2196016, 300)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BdUqM67nYxNL",
        "outputId": "53ffabac-56a5-4448-98e0-ca343487f439"
      },
      "source": [
        "glove_emb_mean, glove_emb_std = -0.005838499, 0.48782197\n",
        "glove_embedding_matrix = np.random.normal(glove_emb_mean, glove_emb_std, (max_features, embed_size))\n",
        "glove_embedding_matrix.shape"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(50000, 300)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "439IQeXgWsv3",
        "outputId": "1dd89322-9d4a-4c7e-ff20-d8c8bc10b127"
      },
      "source": [
        "for k, v in wiki_embedding.items():\n",
        "    if v.shape[0] != 300:\n",
        "        print(k)\n",
        "        print(v)\n",
        "        print(v.shape)"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "999994\n",
            "[300.]\n",
            "(1,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "meFb8f_pYGC8"
      },
      "source": [
        "What does 999994 means? And why it only have one element, not 300?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1qxxi98tYfC7",
        "outputId": "c124ea8f-6dbb-4bce-a100-be6002da9e0c"
      },
      "source": [
        "del wiki_embedding['999994']\n",
        "gc.collect()"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "219"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TKjGLgqNYmC_",
        "outputId": "efdeba94-94c5-4ef2-b443-b5c380a6a3b4"
      },
      "source": [
        "# get_emb_stats(wiki_embedding)"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py:2882: FutureWarning: arrays to stack must be passed as a \"sequence\" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.\n",
            "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(-0.0033469985, 0.109855495, 999994, 300)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y_74Q3yxVoDb",
        "outputId": "6b9b4108-4c91-4925-9a4e-3a5bd2549854"
      },
      "source": [
        "wiki_emb_mean, wiki_emb_std = -0.0033469985, 0.109855495\n",
        "wiki_embedding_matrix = np.random.normal(wiki_emb_mean, wiki_emb_std, (max_features, embed_size))\n",
        "wiki_embedding_matrix.shape"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(50000, 300)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "707ZZdb8ZyRX"
      },
      "source": [
        "def get_emb_stats(embeddings_index):\n",
        "\n",
        "    # Put all embeddings in a numpy matrix\n",
        "    all_embs= embeddings_index.vectors\n",
        "\n",
        "    # Get embedding stats\n",
        "    emb_mean = all_embs.mean()\n",
        "    emb_std = all_embs.std()\n",
        "    \n",
        "    num_embs = all_embs.shape[0]\n",
        "    \n",
        "    emb_size = all_embs.shape[1]\n",
        "    \n",
        "    return emb_mean,emb_std, num_embs, emb_size "
      ],
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0DPP2pJGauFM",
        "outputId": "6177fc5f-9d58-46d1-f539-d5e2b77c7278"
      },
      "source": [
        "# get_emb_stats(google_embedding)"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(-0.003527845, 0.13315111, 3000000, 300)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nHTHt5nQbpe2",
        "outputId": "dc2c5871-1a68-4f78-b02d-83d16c695876"
      },
      "source": [
        "google_emb_mean, google_emb_std = -0.003527845, 0.13315111\n",
        "google_embedding_matrix = np.random.normal(google_emb_mean, google_emb_std, (max_features, embed_size))\n",
        "google_embedding_matrix.shape"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(50000, 300)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TABgPTcaEbta",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67,
          "referenced_widgets": [
            "0d7c237c9b05433e80cb4cc8f22d05fa",
            "18fa003b9bc24a749d2e1fff24615904",
            "570218a9971347dd94114c076894a2c2",
            "9a8a3c4cf2834f02b5f659760a5f2a15",
            "d472fe76a37c4048aeb034eb007f2759",
            "139a747ada2e4b4f968bd238dacbd390",
            "64171f7cf99141ceaec9d343f5fad5f6",
            "f512c346a2ae48dfb22f2c70ab763e70"
          ]
        },
        "outputId": "26b883db-d3f0-4dff-f77f-abb2254251bf"
      },
      "source": [
        "glove_oov = {}\n",
        "wiki_oov = {}\n",
        "google_oov = {}\n",
        "for word, i in tqdm(word_index.items()):\n",
        "    if i >= max_features: continue\n",
        "    if word in glove_embedding:\n",
        "        embedding_vector = glove_embedding[word]\n",
        "        glove_embedding_matrix[i] = embedding_vector\n",
        "    else:\n",
        "        glove_oov[word] = i\n",
        "    if word in wiki_embedding:\n",
        "        embedding_vector = wiki_embedding[word]\n",
        "        wiki_embedding_matrix[i] = embedding_vector\n",
        "    else:\n",
        "        wiki_oov[word] = i\n",
        "    if word in google_embedding:\n",
        "        embedding_vector = google_embedding[word]\n",
        "        google_embedding_matrix[i] = embedding_vector\n",
        "    else:\n",
        "        google_oov[word] = i"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0d7c237c9b05433e80cb4cc8f22d05fa",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=209286.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qnIA_BYQMJFI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "df3d42df-56f2-4b8c-f721-21ae43b2b6ca"
      },
      "source": [
        "print('percentage of oov of glove: {:.2f}%'.format(len(glove_oov) / len(word_index) * 100))\n",
        "print('percentage of oov of wiki: {:.2f}%'.format(len(wiki_oov) / len(word_index) * 100))\n",
        "print('percentage of oov of google: {:.2f}%'.format(len(google_oov) / len(word_index) * 100))"
      ],
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "percentage of oov of glove: 1.93%\n",
            "percentage of oov of wiki: 3.47%\n",
            "percentage of oov of google: 5.64%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rqwPxXC1MRpk"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}