{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Preprocessing.ipynb","provenance":[],"authorship_tag":"ABX9TyMW+h5E8eb/ckpKZVDbPZqg"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"RqIaA_7esIGQ"},"source":["Reference\n","\n","\n","https://www.kaggle.com/strideradu/word2vec-and-gensim-go-go-go"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DJaQHq1uwbWn","executionInfo":{"status":"ok","timestamp":1623595459516,"user_tz":-540,"elapsed":32907,"user":{"displayName":"이창준","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhOCj2fZVTZKKIsh5OkzafCBZp7R8dZp5jeAZKs=s64","userId":"14023147799191402118"}},"outputId":"e8dbb88c-3a5d-4b12-f2d9-5807994408e0"},"source":["import pandas as pd\n","from tqdm import tqdm\n","tqdm.pandas()\n","\n","from google.colab import drive\n","drive.mount('/gdrive')\n","\n","root = '/gdrive/My Drive/ml_project'\n","\n","train = pd.read_csv(root + \"/input/train.csv\")\n","test = pd.read_csv(root + \"/input/test.csv\")\n","print(\"Train shape : \",train.shape)\n","print(\"Test shape : \",test.shape)"],"execution_count":1,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/tqdm/std.py:658: FutureWarning: The Panel class is removed from pandas. Accessing it from the top-level namespace will also be removed in the next version\n","  from pandas import Panel\n"],"name":"stderr"},{"output_type":"stream","text":["Mounted at /gdrive\n","Train shape :  (1306122, 3)\n","Test shape :  (375806, 2)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"WdRlqenjy6h7"},"source":["Import embeddings from zip"]},{"cell_type":"code","metadata":{"id":"Y_7qQjFsxV0Z","executionInfo":{"status":"ok","timestamp":1623595460748,"user_tz":-540,"elapsed":1236,"user":{"displayName":"이창준","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhOCj2fZVTZKKIsh5OkzafCBZp7R8dZp5jeAZKs=s64","userId":"14023147799191402118"}}},"source":["import zipfile\n","from gensim.models import KeyedVectors\n","import numpy as np\n","\n","embeddings_path = root + \"/input/embeddings/embeddings.zip\"\n","glove = 'glove.840B.300d/glove.840B.300d.txt'\n","wiki = 'wiki-news-300d-1M/wiki-news-300d-1M.vec'\n","google = 'GoogleNews-vectors-negative300/GoogleNews-vectors-negative300.bin'\n","para = 'paragram_300_sl999/paragram_300_sl999.txt'\n","\n","\n","def load_embedding(embedding_name):\n","\n","    def get_coefs(word, *arr): return word, np.asarray(arr, dtype='float32')\n","\n","    with zipfile.ZipFile(embeddings_path) as embeddings_zip:\n","        print(\"Found embeddings as a zip file\")\n","\n","        if embedding_name == google:\n","            return KeyedVectors.load_word2vec_format(embeddings_zip.open(google), binary=True)\n","\n","        else:\n","            embedding = []\n","            for o in embeddings_zip.open(embedding_name):\n","                try:\n","                    if len(o.decode('utf-8')) > 100:\n","                        embedding.append(get_coefs(*o.decode('utf-8').split(\" \")))\n","                except:\n","                    pass\n","        \n","        return dict(embedding)"],"execution_count":2,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"z7vqyrCO0jWW"},"source":["Build vocab and check coverage"]},{"cell_type":"code","metadata":{"id":"nNhF8PPK0Qal","executionInfo":{"status":"ok","timestamp":1623595462228,"user_tz":-540,"elapsed":1483,"user":{"displayName":"이창준","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhOCj2fZVTZKKIsh5OkzafCBZp7R8dZp5jeAZKs=s64","userId":"14023147799191402118"}}},"source":["import operator \n","import re\n","import tensorflow as tf\n","from tensorflow import keras\n","from tensorflow.keras.preprocessing.text import Tokenizer\n","def build_vocab(sentences, verbose =  True):\n","    \"\"\"\n","    :param sentences: list of list of words\n","    :return: dictionary of words and their count\n","    \"\"\"\n","    vocab = {}\n","    for sentence in tqdm(sentences, disable = (not verbose)):\n","        for word in sentence:\n","            try:\n","                vocab[word] += 1\n","            except KeyError:\n","                vocab[word] = 1\n","    return vocab\n","\n","def check_coverage(vocab,embeddings_index):\n","    a = {}\n","    oov = {}\n","    k = 0\n","    i = 0\n","    for word in tqdm(vocab):\n","        try:\n","            a[word] = embeddings_index[word]\n","            k += vocab[word]\n","        except:\n","\n","            oov[word] = vocab[word]\n","            i += vocab[word]\n","            pass\n","\n","    print('Found embeddings for {:.2%} of vocab'.format(len(a) / len(vocab)))\n","    print('Found embeddings for  {:.2%} of all text'.format(k / (k + i)))\n","    sorted_x = sorted(oov.items(), key=operator.itemgetter(1))[::-1]\n","\n","    return sorted_x\n","\n","def clean_text(x):\n","\n","    x = str(x)\n","    for punct in \"/-'\":\n","        x = x.replace(punct, ' ')\n","    for punct in '&':\n","        x = x.replace(punct, f' {punct} ')\n","    for punct in '?!.,\"#$%\\'()*+-/:;<=>@[\\\\]^_`{|}~' + '“”’':\n","        x = x.replace(punct, '')\n","    return x\n","\n","def clean_numbers(x):\n","\n","    x = re.sub('[0-9]{5,}', '#####', x)\n","    x = re.sub('[0-9]{4}', '####', x)\n","    x = re.sub('[0-9]{3}', '###', x)\n","    x = re.sub('[0-9]{2}', '##', x)\n","    return x\n","\n","def _get_mispell(mispell_dict):\n","    mispell_re = re.compile('(%s)' % '|'.join(mispell_dict.keys()))\n","    return mispell_dict, mispell_re\n","\n","def clean_short(x): #remove one-length word\n","  shortword = re.compile(r'\\W*\\b\\w\\b')\n","  x = shortword.sub('', x)\n","  return x\n","\n","mispell_dict = {'colour':'color',\n","                'centre':'center',\n","                'didnt':'did not',\n","                'doesnt':'does not',\n","                'isnt':'is not',\n","                'shouldnt':'should not',\n","                'favourite':'favorite',\n","                'travelling':'traveling',\n","                'counselling':'counseling',\n","                'theatre':'theater',\n","                'cancelled':'canceled',\n","                'labour':'labor',\n","                'organisation':'organization',\n","                'wwii':'world war 2',\n","                'citicise':'criticize',\n","                'instagram': 'social medium',\n","                'whatsapp': 'social medium',\n","                'snapchat': 'social medium',\n","                'Snapchat': 'social medium',\n","\n","                }\n","mispellings, mispellings_re = _get_mispell(mispell_dict)\n","\n","def replace_typical_misspell(text):\n","    def replace(match):\n","        return mispellings[match.group(0)]\n","\n","    return mispellings_re.sub(replace, text)"],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CaN1QIse0TAN","executionInfo":{"status":"ok","timestamp":1623596546355,"user_tz":-540,"elapsed":113189,"user":{"displayName":"이창준","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhOCj2fZVTZKKIsh5OkzafCBZp7R8dZp5jeAZKs=s64","userId":"14023147799191402118"}},"outputId":"e1cb247b-0a13-49c4-c8c5-914bd45924c8"},"source":["train_google = train[\"question_text\"]\n","train_other = train[\"question_text\"]\n","\n","train_google = train_google.progress_apply(lambda x: clean_text(x))\n","train_google = train_google.progress_apply(lambda x: clean_numbers(x))\n","train_google = train_google.progress_apply(lambda x: replace_typical_misspell(x))\n","train_google = train_google.progress_apply(lambda x: clean_short(x))\n","sentences = train_google.progress_apply(lambda x: x.split())\n","to_remove = ['a','to','of','and']\n","sentences = [[word for word in sentence if not word in to_remove] for sentence in tqdm(sentences)]\n","vocab_google = build_vocab(sentences)\n","\n","train_other = train_other.progress_apply(lambda x: clean_text(x))\n","train_other = train_other.progress_apply(lambda x: replace_typical_misspell(x))\n","train_other = train_other.progress_apply(lambda x: clean_short(x))\n","sentences = train_other.progress_apply(lambda x: x.split())\n","to_remove = ['a','to','of','and']\n","sentences = [[word for word in sentence if not word in to_remove] for sentence in tqdm(sentences)]\n","vocab_other = build_vocab(sentences)\n"],"execution_count":7,"outputs":[{"output_type":"stream","text":["100%|██████████| 1306122/1306122 [00:11<00:00, 111367.10it/s]\n","100%|██████████| 1306122/1306122 [00:17<00:00, 75958.25it/s]\n","100%|██████████| 1306122/1306122 [00:06<00:00, 203975.01it/s]\n","100%|██████████| 1306122/1306122 [00:10<00:00, 129417.39it/s]\n","100%|██████████| 1306122/1306122 [00:05<00:00, 218110.46it/s]\n","100%|██████████| 1306122/1306122 [00:07<00:00, 170213.23it/s]\n","100%|██████████| 1306122/1306122 [00:05<00:00, 233863.22it/s]\n","100%|██████████| 1306122/1306122 [00:11<00:00, 110736.36it/s]\n","100%|██████████| 1306122/1306122 [00:06<00:00, 205618.96it/s]\n","100%|██████████| 1306122/1306122 [00:10<00:00, 128172.72it/s]\n","100%|██████████| 1306122/1306122 [00:05<00:00, 229819.80it/s]\n","100%|██████████| 1306122/1306122 [00:06<00:00, 198603.64it/s]\n","100%|██████████| 1306122/1306122 [00:05<00:00, 223966.33it/s]\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"_1Xk3lsniLK5","executionInfo":{"status":"ok","timestamp":1623595560509,"user_tz":-540,"elapsed":14,"user":{"displayName":"이창준","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhOCj2fZVTZKKIsh5OkzafCBZp7R8dZp5jeAZKs=s64","userId":"14023147799191402118"}}},"source":["embed_size = 300\n","max_features = 50000\n","def get_emb_stats(embeddings_index):\n","\n","    # Put all embeddings in a numpy matrix\n","    all_embs= np.stack(embeddings_index.values())\n","\n","    # Get embedding stats\n","    emb_mean = all_embs.mean()\n","    emb_std = all_embs.std()\n","    \n","    num_embs = all_embs.shape[0]\n","    \n","    emb_size = all_embs.shape[1]\n","    \n","    return emb_mean,emb_std, num_embs, emb_size\n","\n"],"execution_count":5,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"TEfa-VydmY35"},"source":["Make 4 embeddings"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Sj1Psobq2PXd","executionInfo":{"status":"ok","timestamp":1623597623716,"user_tz":-540,"elapsed":828803,"user":{"displayName":"이창준","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhOCj2fZVTZKKIsh5OkzafCBZp7R8dZp5jeAZKs=s64","userId":"14023147799191402118"}},"outputId":"84a44c69-b607-4d04-dac2-c25deb7770ff"},"source":["tokenizer = Tokenizer(num_words=max_features)\n","tokenizer.fit_on_texts(sentences)\n","word_index = tokenizer.word_index\n","max_features = min(len(word_index), max_features)\n","\n","glove_embedding = load_embedding(glove)\n","oov_glove = check_coverage(vocab_other, glove_embedding)\n","print(oov_glove[:5],\"\\n\",oov_glove[5:10])\n","glove_emb_mean,glove_emb_std, glove_num_embs, glove_emb_size = get_emb_stats(glove_embedding)\n","#glove_emb_matrix = np.random.normal(glove_emb_mean, glove_emb_std, (max_features, embed_size))\n","\n","del glove_embedding\n","wiki_embedding = load_embedding(wiki)\n","oov_wiki = check_coverage(vocab_other, wiki_embedding)\n","print(oov_wiki[:5],\"\\n\",oov_wiki[5:10])\n","wiki_emb_mean,wiki_emb_std, wiki_num_embs, wiki_emb_size = get_emb_stats(wiki_embedding)\n","#wiki_emb_matrix = np.random.normal(wiki_emb_mean, wiki_emb_std, (max_features, embed_size))\n","\n","del wiki_embedding\n","google_embedding = load_embedding(google)\n","oov_google = check_coverage(vocab_google, google_embedding)\n","print(oov_google[:5],\"\\n\",oov_google[5:10])\n","#google_emb_mean,google_emb_std, google_num_embs, google_emb_size = get_emb_stats(google_embedding)\n","#google_emb_matrix = np.random.normal(google_emb_mean, google_emb_std, (max_features, embed_size))\n","\n","del google_embedding\n","para_embedding = load_embedding(para)\n","oov_para = check_coverage(vocab_other, para_embedding)\n","print(oov_para[:5],\"\\n\",oov_para[5:10])\n","para_emb_mean,para_emb_std, para_num_embs, para_emb_size = get_emb_stats(para_embedding)\n","#para_emb_matrix = np.random.normal(para_emb_mean, para_emb_std, (max_features, embed_size))\n","del para_embedding"],"execution_count":17,"outputs":[{"output_type":"stream","text":["Found embeddings as a zip file\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 238716/238716 [00:00<00:00, 454490.87it/s]\n","/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py:2882: FutureWarning: arrays to stack must be passed as a \"sequence\" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.\n","  exec(code_obj, self.user_global_ns, self.user_ns)\n"],"name":"stderr"},{"output_type":"stream","text":["Found embeddings for 72.38% of vocab\n","Found embeddings for  99.41% of all text\n","[('Quorans', 858), ('Brexit', 493), ('cryptocurrencies', 481), ('Redmi', 380), ('₹', 178)] \n"," [('OnePlus', 125), ('UCEED', 124), ('GDPR', 107), ('Blockchain', 107), ('demonetisation', 106)]\n","Found embeddings as a zip file\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 238716/238716 [00:00<00:00, 656729.70it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["Found embeddings for 65.34% of vocab\n","Found embeddings for  99.23% of all text\n","[('Quorans', 858), ('BITSAT', 564), ('COMEDK', 352), ('KVPY', 349), ('Quoran', 308)] \n"," [('mtech', 281), ('WBJEE', 231), ('bcom', 199), ('articleship', 191), ('VITEEE', 182)]\n","Found embeddings as a zip file\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 238716/238716 [00:00<00:00, 267898.68it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["Found embeddings for 60.98% of vocab\n","Found embeddings for  98.95% of all text\n","[('bitcoin', 987), ('Quorans', 858), ('cryptocurrency', 822), ('btech', 632), ('Brexit', 493)] \n"," [('cryptocurrencies', 481), ('blockchain', 474), ('behaviour', 468), ('upvotes', 432), ('programme', 402)]\n","Found embeddings as a zip file\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 238716/238716 [00:00<00:00, 449850.26it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["Found embeddings for 38.85% of vocab\n","Found embeddings for  80.88% of all text\n","[('What', 430843), ('How', 263113), ('Why', 145160), ('Is', 108973), ('Can', 53043)] \n"," [('Which', 47352), ('Do', 40148), ('If', 34767), ('India', 32727), ('Are', 29254)]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"0yixd4cTw1QS"},"source":[""],"execution_count":null,"outputs":[]}]}