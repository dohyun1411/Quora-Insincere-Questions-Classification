{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "version": "3.6.4",
      "file_extension": ".py",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "name": "python",
      "mimetype": "text/x-python"
    },
    "colab": {
      "name": "qiqc-sub1.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dohyun1411/Quora-Insincere-Questions-Classification/blob/main/qiqc_sub1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MjG4VaNGNC_F",
        "execution": {
          "iopub.status.busy": "2021-06-18T07:51:23.804599Z",
          "iopub.execute_input": "2021-06-18T07:51:23.804948Z",
          "iopub.status.idle": "2021-06-18T07:51:29.675083Z",
          "shell.execute_reply.started": "2021-06-18T07:51:23.804872Z",
          "shell.execute_reply": "2021-06-18T07:51:29.674242Z"
        },
        "trusted": true
      },
      "source": [
        "import re\n",
        "import gc\n",
        "import random\n",
        "import os\n",
        "\n",
        "from tqdm.auto import tqdm\n",
        "tqdm.pandas()\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from sklearn.model_selection import train_test_split, KFold, StratifiedKFold\n",
        "from sklearn.metrics import f1_score\n",
        "\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "from tensorflow.compat.v1.keras.layers import CuDNNLSTM\n",
        "from keras.layers import Dense, Input, Embedding, Dropout, Activation, Conv1D\n",
        "from keras.layers import Bidirectional, GlobalMaxPool1D, GlobalMaxPooling1D, GlobalAveragePooling1D\n",
        "from keras.layers import Input, Embedding, Dense, Conv2D, MaxPool2D, concatenate\n",
        "from keras.layers import Reshape, Flatten, Concatenate, Dropout, SpatialDropout1D\n",
        "from keras.optimizers import Adam\n",
        "from keras.models import Model\n",
        "from keras.engine.topology import Layer\n",
        "from keras import initializers, regularizers, constraints, optimizers, layers\n",
        "\n",
        "from keras.layers import *\n",
        "from keras.models import *\n",
        "from keras import initializers, regularizers, constraints, optimizers, layers\n",
        "from keras.initializers import *\n",
        "from keras.optimizers import *\n",
        "import keras.backend as K\n",
        "from keras.callbacks import *\n",
        "import tensorflow as tf"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "seq4dn8WNkPd"
      },
      "source": [
        "Config"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n1YYJL-KNl6a",
        "execution": {
          "iopub.status.busy": "2021-06-18T07:51:29.676474Z",
          "iopub.execute_input": "2021-06-18T07:51:29.676801Z",
          "iopub.status.idle": "2021-06-18T07:51:29.681022Z",
          "shell.execute_reply.started": "2021-06-18T07:51:29.676767Z",
          "shell.execute_reply": "2021-06-18T07:51:29.680256Z"
        },
        "trusted": true
      },
      "source": [
        "n_splits = 5\n",
        "input_path = '../input/quora-insincere-questions-classification'\n",
        "max_features = None # 120000\n",
        "embed_size = 300\n",
        "maxlen = 55 # None\n",
        "batch_size = 2048\n",
        "max_epoch = 5"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VPjrREs66UgD"
      },
      "source": [
        "Load train and test data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w45w3ftY6WhC",
        "execution": {
          "iopub.status.busy": "2021-06-18T07:51:29.683729Z",
          "iopub.execute_input": "2021-06-18T07:51:29.684296Z",
          "iopub.status.idle": "2021-06-18T07:51:34.32382Z",
          "shell.execute_reply.started": "2021-06-18T07:51:29.684257Z",
          "shell.execute_reply": "2021-06-18T07:51:34.323019Z"
        },
        "trusted": true
      },
      "source": [
        "train_path = os.path.join(input_path, 'train.csv')\n",
        "test_path = os.path.join(input_path, 'test.csv')\n",
        "\n",
        "train_df = pd.read_csv(train_path)\n",
        "test_df = pd.read_csv(test_path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D0ko9_3V6qRO"
      },
      "source": [
        "Tokenize"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-06-18T07:51:34.325412Z",
          "iopub.execute_input": "2021-06-18T07:51:34.325731Z",
          "iopub.status.idle": "2021-06-18T07:51:34.331926Z",
          "shell.execute_reply.started": "2021-06-18T07:51:34.325697Z",
          "shell.execute_reply": "2021-06-18T07:51:34.33108Z"
        },
        "trusted": true,
        "id": "XuTL6YkdaDh7"
      },
      "source": [
        "puncts = '´‘’“”…!#$%&()*+,-./:;<=>?@[\\]^_`{|}~\"' + \"'\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tjUtD9vy6Woh",
        "execution": {
          "iopub.status.busy": "2021-06-18T07:51:34.33393Z",
          "iopub.execute_input": "2021-06-18T07:51:34.334627Z",
          "iopub.status.idle": "2021-06-18T07:51:34.342685Z",
          "shell.execute_reply.started": "2021-06-18T07:51:34.334589Z",
          "shell.execute_reply": "2021-06-18T07:51:34.341913Z"
        },
        "trusted": true
      },
      "source": [
        "to_exclude = ''\n",
        "to_tokenize = puncts\n",
        "\n",
        "tokenizer = Tokenizer(num_words=max_features, filters=to_exclude, lower=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xm9DColL6WrG",
        "execution": {
          "iopub.status.busy": "2021-06-18T07:51:34.343779Z",
          "iopub.execute_input": "2021-06-18T07:51:34.344035Z",
          "iopub.status.idle": "2021-06-18T07:51:34.513186Z",
          "shell.execute_reply.started": "2021-06-18T07:51:34.344011Z",
          "shell.execute_reply": "2021-06-18T07:51:34.512346Z"
        },
        "trusted": true
      },
      "source": [
        "train_text = train_df[\"question_text\"].fillna(\"_na_\")\n",
        "test_text = test_df[\"question_text\"].fillna(\"_na_\")\n",
        "train_y = train_df['target'].values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wlpfmE7Y6pjF",
        "execution": {
          "iopub.status.busy": "2021-06-18T07:51:34.515161Z",
          "iopub.execute_input": "2021-06-18T07:51:34.515407Z",
          "iopub.status.idle": "2021-06-18T07:51:51.237735Z",
          "shell.execute_reply.started": "2021-06-18T07:51:34.515383Z",
          "shell.execute_reply": "2021-06-18T07:51:51.236654Z"
        },
        "trusted": true
      },
      "source": [
        "train_text = train_text.progress_apply(lambda x: re.sub(r'(['+to_tokenize+'])', r' \\1', x)).values\n",
        "test_text = test_text.progress_apply(lambda x: re.sub(r'(['+to_tokenize+'])', r' \\1', x)).values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CHY6XMyJ6pmt",
        "execution": {
          "iopub.status.busy": "2021-06-18T07:51:51.240767Z",
          "iopub.execute_input": "2021-06-18T07:51:51.241161Z",
          "iopub.status.idle": "2021-06-18T07:51:51.347645Z",
          "shell.execute_reply.started": "2021-06-18T07:51:51.241122Z",
          "shell.execute_reply": "2021-06-18T07:51:51.346665Z"
        },
        "trusted": true
      },
      "source": [
        "text = list(train_text) + list(test_text)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BDVp0_Lo65bf",
        "execution": {
          "iopub.status.busy": "2021-06-18T07:51:51.349844Z",
          "iopub.execute_input": "2021-06-18T07:51:51.350419Z",
          "iopub.status.idle": "2021-06-18T07:52:16.874063Z",
          "shell.execute_reply.started": "2021-06-18T07:51:51.350377Z",
          "shell.execute_reply": "2021-06-18T07:52:16.873165Z"
        },
        "trusted": true
      },
      "source": [
        "tokenizer.fit_on_texts(text)\n",
        "word_index = tokenizer.word_index"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NpdI2Ic3_2RU",
        "execution": {
          "iopub.status.busy": "2021-06-18T07:52:16.875308Z",
          "iopub.execute_input": "2021-06-18T07:52:16.875649Z",
          "iopub.status.idle": "2021-06-18T07:52:50.316914Z",
          "shell.execute_reply.started": "2021-06-18T07:52:16.875603Z",
          "shell.execute_reply": "2021-06-18T07:52:50.316107Z"
        },
        "trusted": true
      },
      "source": [
        "train_X = tokenizer.texts_to_sequences(train_text)\n",
        "test_X = tokenizer.texts_to_sequences(test_text)\n",
        "\n",
        "train_X = pad_sequences(train_X, maxlen=maxlen, truncating = \"pre\")\n",
        "test_X = pad_sequences(test_X, maxlen=maxlen, truncating = \"pre\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yGfBuPzG85Ta",
        "execution": {
          "iopub.status.busy": "2021-06-18T07:52:50.318252Z",
          "iopub.execute_input": "2021-06-18T07:52:50.318581Z",
          "iopub.status.idle": "2021-06-18T07:52:50.323609Z",
          "shell.execute_reply.started": "2021-06-18T07:52:50.318545Z",
          "shell.execute_reply": "2021-06-18T07:52:50.322743Z"
        },
        "trusted": true
      },
      "source": [
        "max_features = len(word_index) if max_features is None else max_features\n",
        "# maxlen = max({len(seq) for seq in train_X} | {len(seq) for seq in val_X} | {len(seq) for seq in test_X}) if maxlen is None else maxlen"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "faLW2hAoM8_X"
      },
      "source": [
        "Load embedding"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N7uCdzyaM6Qh",
        "execution": {
          "iopub.status.busy": "2021-06-18T07:52:50.324916Z",
          "iopub.execute_input": "2021-06-18T07:52:50.325418Z",
          "iopub.status.idle": "2021-06-18T07:52:50.468983Z",
          "shell.execute_reply.started": "2021-06-18T07:52:50.325381Z",
          "shell.execute_reply": "2021-06-18T07:52:50.468147Z"
        },
        "trusted": true
      },
      "source": [
        "import zipfile\n",
        "from gensim.models import KeyedVectors\n",
        "\n",
        "embeddings_path = os.path.join(input_path, 'embeddings.zip')\n",
        "\n",
        "glove = 'glove.840B.300d/glove.840B.300d.txt'\n",
        "wiki = 'wiki-news-300d-1M/wiki-news-300d-1M.vec'\n",
        "google = 'GoogleNews-vectors-negative300/GoogleNews-vectors-negative300.bin'\n",
        "para = 'paragram_300_sl999/paragram_300_sl999.txt'\n",
        "\n",
        "\n",
        "def load_embedding(embedding_name):\n",
        "\n",
        "    def get_coefs(word, *arr): return word, np.asarray(arr, dtype='float32')\n",
        "\n",
        "    with zipfile.ZipFile(embeddings_path) as embeddings_zip:\n",
        "\n",
        "        if embedding_name == google:\n",
        "            return KeyedVectors.load_word2vec_format(embeddings_zip.open(google), binary=True)\n",
        "\n",
        "        else:\n",
        "            embedding = []\n",
        "            for o in embeddings_zip.open(embedding_name):\n",
        "                try:\n",
        "                    if len(o.decode('utf-8')) > 100:\n",
        "                        embedding.append(get_coefs(*o.decode('utf-8').split(\" \")))\n",
        "                except:\n",
        "                    pass\n",
        "        \n",
        "        return dict(embedding)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cu0T-YHfOt0L",
        "execution": {
          "iopub.status.busy": "2021-06-18T07:52:50.471982Z",
          "iopub.execute_input": "2021-06-18T07:52:50.472252Z",
          "iopub.status.idle": "2021-06-18T07:52:50.958327Z",
          "shell.execute_reply.started": "2021-06-18T07:52:50.472227Z",
          "shell.execute_reply": "2021-06-18T07:52:50.957477Z"
        },
        "trusted": true
      },
      "source": [
        "import nltk\n",
        "# nltk.download('wordnet')\n",
        "\n",
        "from nltk.stem import PorterStemmer\n",
        "from nltk.stem import LancasterStemmer\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "s = PorterStemmer()\n",
        "l = LancasterStemmer()\n",
        "n = WordNetLemmatizer()\n",
        "\n",
        "def is_in_emb(word, i, embedding, emb_matrix):\n",
        "\n",
        "    if word in embedding:\n",
        "        emb_matrix[i] = embedding[word]\n",
        "        return True\n",
        "    \n",
        "    tmp = word.lower()\n",
        "    if tmp in embedding:\n",
        "        emb_matrix[i] = embedding[tmp]\n",
        "        return True\n",
        "    \n",
        "    tmp = word.upper()\n",
        "    if tmp in embedding:\n",
        "        emb_matrix[i] = embedding[tmp]\n",
        "        return True\n",
        "\n",
        "    tmp = word.capitalize()\n",
        "    if tmp in embedding:\n",
        "        emb_matrix[i] = embedding[tmp]\n",
        "        return True\n",
        "\n",
        "    tmp = s.stem(word)\n",
        "    if tmp in embedding:\n",
        "        emb_matrix[i] = embedding[tmp]\n",
        "        return True\n",
        "    \n",
        "    tmp = l.stem(word)\n",
        "    if tmp in embedding:\n",
        "        emb_matrix[i] = embedding[tmp]\n",
        "        return True\n",
        "    \n",
        "    tmp = n.lemmatize(word)\n",
        "    if tmp in embedding:\n",
        "        emb_matrix[i] = embedding[tmp]\n",
        "        return True\n",
        "    \n",
        "    return False"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wp2R6V811SHp",
        "execution": {
          "iopub.status.busy": "2021-06-18T07:52:50.959618Z",
          "iopub.execute_input": "2021-06-18T07:52:50.959959Z",
          "iopub.status.idle": "2021-06-18T07:52:50.965852Z",
          "shell.execute_reply.started": "2021-06-18T07:52:50.959925Z",
          "shell.execute_reply": "2021-06-18T07:52:50.965047Z"
        },
        "trusted": true
      },
      "source": [
        "# puncts = '´‘’“”…!#$%&()*+,-./:;<=>?@[\\]^_`{|}~\"' + \"'\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AaAoKuAoM6Lg",
        "execution": {
          "iopub.status.busy": "2021-06-18T08:04:21.213668Z",
          "iopub.execute_input": "2021-06-18T08:04:21.213983Z",
          "iopub.status.idle": "2021-06-18T08:04:21.225485Z",
          "shell.execute_reply.started": "2021-06-18T08:04:21.213955Z",
          "shell.execute_reply": "2021-06-18T08:04:21.223096Z"
        },
        "trusted": true
      },
      "source": [
        "def load_emb_matrix(embedding_name):\n",
        "\n",
        "    embedding = load_embedding(embedding_name)\n",
        "    if embedding_name == glove: emb_mean, emb_std = -0.005838499, 0.48782197\n",
        "    if embedding_name == wiki: emb_mean, emb_std = -0.0033469985, 0.109855495\n",
        "    if embedding_name == google: emb_mean, emb_std = -0.003527845, 0.13315111\n",
        "    if embedding_name == para: emb_mean, emb_std = -0.0053248387, 0.49346521\n",
        "    emb_matrix = np.random.normal(emb_mean, emb_std, (max_features + 1, embed_size))\n",
        "    for word, i in tqdm(word_index.items()):\n",
        "        # i -= 1\n",
        "        assert i >= 0\n",
        "\n",
        "        if i >= max_features: continue\n",
        "\n",
        "        if is_in_emb(word, i, embedding, emb_matrix): continue\n",
        "\n",
        "        if embedding_name == google:\n",
        "\n",
        "            tmp = re.sub('[0-9]{5,}', '#####', word)\n",
        "            tmp = re.sub('[0-9]{4}', '####', tmp)\n",
        "            tmp = re.sub('[0-9]{3}', '###', tmp)\n",
        "            tmp = re.sub('[0-9]{2}', '##', tmp)\n",
        "            if is_in_emb(tmp, i, embedding, emb_matrix): continue\n",
        "\n",
        "            for punct in puncts:\n",
        "                tmp = tmp.replace(punct, '')\n",
        "            if is_in_emb(tmp, i, embedding, emb_matrix): continue\n",
        "\n",
        "        else:\n",
        "        \n",
        "            tmp = word\n",
        "            for punct in puncts:\n",
        "                tmp = tmp.replace(punct, '')\n",
        "            if is_in_emb(tmp, i, embedding, emb_matrix): continue\n",
        "\n",
        "            for num in '0123456789':\n",
        "                tmp = tmp.replace(num, '')\n",
        "            if is_in_emb(tmp, i, embedding, emb_matrix): continue\n",
        "    \n",
        "\n",
        "    del embedding\n",
        "    gc.collect()\n",
        "    return emb_matrix"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "askqlJwBM6DY",
        "execution": {
          "iopub.status.busy": "2021-06-18T08:04:24.845435Z",
          "iopub.execute_input": "2021-06-18T08:04:24.84578Z",
          "iopub.status.idle": "2021-06-18T08:09:44.978961Z",
          "shell.execute_reply.started": "2021-06-18T08:04:24.845752Z",
          "shell.execute_reply": "2021-06-18T08:09:44.977927Z"
        },
        "trusted": true
      },
      "source": [
        "%%time\n",
        "emb_matrix = load_emb_matrix(glove)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yx7a7vz_M6A0",
        "execution": {
          "iopub.status.busy": "2021-06-18T07:59:15.815474Z",
          "iopub.execute_input": "2021-06-18T07:59:15.815948Z",
          "iopub.status.idle": "2021-06-18T07:59:15.820949Z",
          "shell.execute_reply.started": "2021-06-18T07:59:15.815911Z",
          "shell.execute_reply": "2021-06-18T07:59:15.820169Z"
        },
        "trusted": true
      },
      "source": [
        "%%time\n",
        "# para_emb_matrix = load_emb_matrix(para)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-06-18T07:59:15.822177Z",
          "iopub.execute_input": "2021-06-18T07:59:15.822657Z",
          "iopub.status.idle": "2021-06-18T07:59:15.837186Z",
          "shell.execute_reply.started": "2021-06-18T07:59:15.822621Z",
          "shell.execute_reply": "2021-06-18T07:59:15.836294Z"
        },
        "trusted": true,
        "id": "_gZPgRlnaDiE"
      },
      "source": [
        "%%time\n",
        "# google_emb_matrix = load_emb_matrix(google)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fQk2qcLAM5-V",
        "execution": {
          "iopub.status.busy": "2021-06-18T07:59:15.838542Z",
          "iopub.execute_input": "2021-06-18T07:59:15.83892Z",
          "iopub.status.idle": "2021-06-18T07:59:15.847475Z",
          "shell.execute_reply.started": "2021-06-18T07:59:15.838883Z",
          "shell.execute_reply": "2021-06-18T07:59:15.846672Z"
        },
        "trusted": true
      },
      "source": [
        "# emb_matrix = np.mean((0.5 * glove_emb_matrix, 0.5 * para_emb_matrix), axis=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YZQjJW4q5822"
      },
      "source": [
        "Train and Test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-06-18T08:10:15.968358Z",
          "iopub.execute_input": "2021-06-18T08:10:15.968699Z",
          "iopub.status.idle": "2021-06-18T08:10:15.975616Z",
          "shell.execute_reply.started": "2021-06-18T08:10:15.968648Z",
          "shell.execute_reply": "2021-06-18T08:10:15.974498Z"
        },
        "trusted": true,
        "id": "UIPMRUBfaDiH"
      },
      "source": [
        "class MyModel(tf.keras.Model):\n",
        "    def __init__(self):\n",
        "        super(MyModel, self).__init__()\n",
        "        self.embed = Embedding(max_features + 1, embed_size, weights = [emb_matrix], trainable = False)\n",
        "        self.rnn = Sequential([\n",
        "            SpatialDropout1D(0.3),\n",
        "            Bidirectional(LSTM(128, return_sequences = True)),\n",
        "            Bidirectional(LSTM(128, return_sequences = True)),\n",
        "            Conv1D(128, 3, activation = \"relu\"),\n",
        "            GlobalMaxPool1D(),\n",
        "            Dense(64, activation = \"relu\"),\n",
        "            Dropout(0.2),\n",
        "            Dense(1, activation = \"sigmoid\")\n",
        "        ])\n",
        "\n",
        "    def call(self, inputs):\n",
        "        x = self.embed(inputs)\n",
        "        x = self.rnn(x)\n",
        "        return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_kBcGw5MaDiH"
      },
      "source": [
        "cv = True"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-06-18T08:10:16.476512Z",
          "iopub.execute_input": "2021-06-18T08:10:16.476841Z",
          "iopub.status.idle": "2021-06-18T08:13:51.439036Z",
          "shell.execute_reply.started": "2021-06-18T08:10:16.476811Z",
          "shell.execute_reply": "2021-06-18T08:13:51.438157Z"
        },
        "trusted": true,
        "id": "U37my9QLaDiI"
      },
      "source": [
        "splits = list(StratifiedKFold(n_splits=n_splits, shuffle=True).split(train_X, train_y))\n",
        "for i, (train_idx, val_idx) in enumerate(splits):\n",
        "    print(f'Fold {i + 1}')\n",
        "\n",
        "    model = MyModel()\n",
        "    model.compile(loss = 'binary_crossentropy', optimizer = 'Adam', metrics = ['binary_accuracy'])\n",
        "\n",
        "    train_X_fold = train_X[train_idx.astype(int)]\n",
        "    train_y_fold = train_y[train_idx.astype(int)]\n",
        "    val_X_fold = train_X[val_idx.astype(int)]\n",
        "    val_y_fold = train_y[val_idx.astype(int)]\n",
        "\n",
        "    model.fit(train_X_fold, train_y_fold, batch_size=batch_size, epochs=max_epoch, validation_data=(val_X_fold, val_y_fold))\n",
        "\n",
        "    if i == 0:\n",
        "        predicted = model.predict(test_X, batch_size=batch_size)\n",
        "    else:\n",
        "        predicted = predicted + model.predict(test_X, batch_size=batch_size)\n",
        "    \n",
        "    if not cv: break\n",
        "\n",
        "if cv: predicted = predicted / len(splits)\n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-06-18T07:59:16.224579Z",
          "iopub.status.idle": "2021-06-18T07:59:16.225294Z"
        },
        "trusted": true,
        "id": "9TBiY_HIaDiI"
      },
      "source": [
        "res = [0 if x < 0.35 else 1 for x in predicted]\n",
        "submission = pd.DataFrame({'qid': test_df['qid'][:len(res)], 'prediction': res}, columns=['qid', 'prediction'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-06-18T07:59:16.226459Z",
          "iopub.status.idle": "2021-06-18T07:59:16.227044Z"
        },
        "trusted": true,
        "id": "omkdHm10aDiJ"
      },
      "source": [
        "submission.to_csv('./submission.csv', index=False)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
